{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sprint20.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Fq5VA0zYs1Me","colab_type":"text"},"source":["# Sprint20 セグメンテーション2\n","\n","## 1.このSprintについて\n","\n","### Sprintの目的\n","- セグメンテーションの精度を向上させる\n","\n","### どのように学ぶか\n","Kaggleコンペティションの情報を参考にセグメンテーションの精度を向上させます。\n","\n","## 2.セグメンテーションの精度向上\n","前回に引き続きTGS Salt Identification Challengのデータセットの学習・推定を行います。\n","\n","TGS Salt Identification Challenge | Kaggle\n","\n","### 【問題1】コードレビュー\n","転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n","\n","#### 《視点例》\n","\n","前回使用した実装とはどのように違うのか\n","転移学習をどのように行っているか"]},{"cell_type":"code","metadata":{"id":"DRWB9f8k-iZt","colab_type":"code","outputId":"5ff2b522-5093-4ded-aee1-95e384aa7099","executionInfo":{"status":"ok","timestamp":1569390509442,"user_tz":-540,"elapsed":5509,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["!pip install kaggle"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.6.16)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n","Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lmk9h1pc-q26","colab_type":"code","outputId":"2968651b-5753-4732-be4f-b264c452ac4b","executionInfo":{"status":"ok","timestamp":1572439776535,"user_tz":-540,"elapsed":17774,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GMHMl342-rXD","colab_type":"code","colab":{}},"source":["mkdir .kaggle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JO2SCr6w94YF","colab_type":"code","colab":{}},"source":["# https://www.kaggle.com/　へアクセスし、ログイン後に右上のプロフィール画像をクリック、さらに\"My Account\"をクリックする\n","# このサイトの「API」項目にある\"Create New API Token\"をクリックすると、kaggle.jsonファイルが自動的にダウンロードされる\n","# ローカルで、kaggle.json（ダウンロードフォルダにあるはず）をエディターで開く。\n","# このセルの以下のコードにある token = {'username':'***','key':'***'} における「***」部分を、\n","# ダウンロードしたkaggle.jsonを参照して書き換え、このセルを実行する\n","\n","import json\n","\n","token = {'username':'kjkakh','key':'782e5d8c379bb89b43fcb7e2f94da336'}\n","with open('/content/.kaggle/kaggle.json', 'w') as file:\n","    json.dump(token, file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmaDQIcM9tOo","colab_type":"code","colab":{}},"source":["!chmod 600 /content/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXL8M7Om9vSx","colab_type":"code","colab":{}},"source":["!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCe5SCVQ-UP-","colab_type":"code","outputId":"e9da7e95-a83f-4cb0-e6d0-d091841856c2","executionInfo":{"status":"ok","timestamp":1572439781028,"user_tz":-540,"elapsed":3486,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["import gc\n","import glob\n","import os\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from tqdm import tqdm\n","\n","from keras import optimizers\n","from keras.callbacks import *\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from keras.layers import *\n","from keras.models import Model, load_model, save_model\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\n","from keras.applications.resnet50 import ResNet50, preprocess_input\n","\n","%matplotlib inline"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"XHSmUEb1-ZN2","colab_type":"code","colab":{}},"source":["plt.rcParams['figure.figsize'] = (12, 9)\n","# plt.style.use('ggplot')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvNRqm0x-d1m","colab_type":"code","colab":{}},"source":["def compute_coverage(df, masks):\n","    \n","    df = df.copy()\n","    \n","    def cov_to_class(val):\n","        for i in range(0, 11):\n","            if val * 10 <= i:\n","                return i\n","\n","    # Output percentage of area covered by class\n","    df['coverage'] = np.mean(masks, axis=(1, 2))\n","    # Coverage must be split into bins, otherwise stratified split will not be possible,\n","    # because each coverage will occur only once.\n","    df['coverage_class'] = df.coverage.map(\n","        cov_to_class)\n","\n","    return df\n","\n","\n","def create_depth_abs_channels(image_tensor):\n","    image_tensor = image_tensor.astype(np.float32)\n","    h, w, c = image_tensor.shape\n","    for row, const in enumerate(np.linspace(0, 1, h)):\n","        image_tensor[row, :, 1] = const\n","    image_tensor[:, :, 2] = (\n","        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n","\n","    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n","    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n","    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n","    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n","    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n","\n","    return image_tensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Mu9oHfd-hat","colab_type":"code","outputId":"2604f745-043d-4d1a-ba0c-1b1ffd6d4d49","executionInfo":{"status":"ok","timestamp":1572439809955,"user_tz":-540,"elapsed":1629,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["train = pd.read_csv('/content/drive/My Drive/Sprint19/train.csv')\n","test = pd.read_csv('/content/drive/My Drive/Sprint19/sample_submission.csv')\n","depth = pd.read_csv('/content/drive/My Drive/Sprint19/depths.csv')\n","\n","#train_src = '../input/train/'\n","\n","print('train:\\n{}'.format(train.head()))\n","print('\\ntest:\\n{}'.format(test.head()))\n","\n","\n","train = train.merge(depth, how='left', on='id')\n","test = test.merge(depth, how='left', on='id')\n","\n","print('\\n{}'.format(train.head()))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["train:\n","           id                                           rle_mask\n","0  575d24d81d                                                NaN\n","1  a266a2a9df                                          5051 5151\n","2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n","3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n","4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n","\n","test:\n","           id rle_mask\n","0  155410d6fa      1 1\n","1  78b32781d1      1 1\n","2  63db2a476a      1 1\n","3  17bfcdb967      1 1\n","4  7ea0fd3c88      1 1\n","\n","           id                                           rle_mask    z\n","0  575d24d81d                                                NaN  843\n","1  a266a2a9df                                          5051 5151  794\n","2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n","3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n","4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Z3N6pZR-3Q9","colab_type":"code","colab":{}},"source":["X_train = np.asarray(\n","    [cv2.imread('/content/drive/My Drive/Sprint19/train_data/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n","    dtype=np.uint8) / 255.\n","y_train = np.asarray(\n","    [cv2.imread('/content/drive/My Drive/Sprint19/train_data/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n","    dtype=np.uint8) / 255.\n","\n","print(X_train.shape, y_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3W8hWb2_G3O","colab_type":"code","outputId":"23727860-6652-4526-e100-0b6f5c554fba","executionInfo":{"status":"ok","timestamp":1569395246727,"user_tz":-540,"elapsed":1531,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":373}},"source":["random_index = np.random.randint(0, X_train.shape[0])\n","\n","fig, ax = plt.subplots(1, 2)\n","\n","ax[0].imshow(X_train[random_index], cmap='gray')\n","ax[1].imshow(y_train[random_index], cmap='gray')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fcc5d976b00>"]},"metadata":{"tags":[]},"execution_count":7},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<Figure size 864x648 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"teCF_YmhAjdu","colab_type":"code","colab":{}},"source":["train = compute_coverage(train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJCLozN4A8A2","colab_type":"code","outputId":"28f6d4b5-f92a-4060-b631-68042262b63c","executionInfo":{"status":"ok","timestamp":1569395271097,"user_tz":-540,"elapsed":18406,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["kfold = StratifiedKFold(n_splits=5, random_state=1337)\n","\n","# Add channel features\n","X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n","X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n","\n","# Resize to 224x224, default ResNet50 image size\n","X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n","y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n","\n","\n","for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n","    \n","    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n","    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n","    \n","    break\n","    \n","\n","y_tr = np.expand_dims(y_tr, axis=-1)\n","y_val = np.expand_dims(y_val, axis=-1)\n","\n","print(X_tr.shape, y_tr.shape)\n","print(X_val.shape, y_val.shape)\n","\n","\n","del X_train_ch, y_resized\n","del X_resized\n","gc.collect()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(3196, 224, 224, 3) (3196, 224, 224, 1)\n","(804, 224, 224, 3) (804, 224, 224, 1)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["81"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"gzPSA0z5A8c8","colab_type":"code","colab":{}},"source":["from keras.losses import binary_crossentropy\n","\n","\n","# Dice & combined\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred = K.cast(y_pred, 'float32')\n","    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n","    intersection = y_true_f * y_pred_f\n","    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n","    return score\n","\n","\n","def dice_loss(y_true, y_pred):\n","    smooth = 1.\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = y_true_f * y_pred_f\n","    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","    return 1. - score\n","\n","\n","def bce_dice_loss(y_true, y_pred):\n","    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n","\n","\n","def bce_logdice_loss(y_true, y_pred):\n","    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n","\n","\n","\n","# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n","def lovasz_grad(gt_sorted):\n","    \"\"\"\n","    Computes gradient of the Lovasz extension w.r.t sorted errors\n","    See Alg. 1 in paper\n","    \"\"\"\n","    gts = tf.reduce_sum(gt_sorted)\n","    intersection = gts - tf.cumsum(gt_sorted)\n","    union = gts + tf.cumsum(1. - gt_sorted)\n","    jaccard = 1. - intersection / union\n","    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n","    return jaccard\n","\n","\n","# --------------------------- BINARY LOSSES ---------------------------\n","\n","def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n","      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n","      per_image: compute the loss per image instead of per batch\n","      ignore: void class id\n","    \"\"\"\n","    if per_image:\n","        def treat_image(log_lab):\n","            log, lab = log_lab\n","            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n","            log, lab = flatten_binary_scores(log, lab, ignore)\n","            return lovasz_hinge_flat(log, lab)\n","        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n","        loss = tf.reduce_mean(losses)\n","    else:\n","        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n","    return loss\n","\n","\n","def lovasz_hinge_flat(logits, labels):\n","    \"\"\"\n","    Binary Lovasz hinge loss\n","      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n","      labels: [P] Tensor, binary ground truth labels (0 or 1)\n","      ignore: label to ignore\n","    \"\"\"\n","\n","    def compute_loss():\n","        labelsf = tf.cast(labels, logits.dtype)\n","        signs = 2. * labelsf - 1.\n","        errors = 1. - logits * tf.stop_gradient(signs)\n","        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n","        gt_sorted = tf.gather(labelsf, perm)\n","        grad = lovasz_grad(gt_sorted)\n","        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n","        return loss\n","\n","    # deal with the void prediction case (only void pixels)\n","    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n","                   lambda: tf.reduce_sum(logits) * 0.,\n","                   compute_loss,\n","                   strict=True,\n","                   name=\"loss\"\n","                   )\n","    return loss\n","\n","\n","def flatten_binary_scores(scores, labels, ignore=None):\n","    \"\"\"\n","    Flattens predictions in the batch (binary case)\n","    Remove labels equal to 'ignore'\n","    \"\"\"\n","    scores = tf.reshape(scores, (-1,))\n","    labels = tf.reshape(labels, (-1,))\n","    if ignore is None:\n","        return scores, labels\n","    valid = tf.not_equal(labels, ignore)\n","    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n","    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n","    return vscores, vlabels\n","\n","\n","def lovasz_loss(y_true, y_pred):\n","    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n","    #logits = K.log(y_pred / (1. - y_pred))\n","    logits = y_pred #Jiaxin\n","    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n","    return loss\n","\n","\n","# IoU metric for observation during training\n","# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n","def get_iou_vector(A, B):\n","    # Numpy version    \n","    batch_size = A.shape[0]\n","    metric = 0.0\n","    for batch in range(batch_size):\n","        t, p = A[batch], B[batch]\n","        true = np.sum(t)\n","        pred = np.sum(p)\n","        \n","        # deal with empty mask first\n","        if true == 0:\n","            metric += (pred == 0)\n","            continue\n","        \n","        # non empty mask case.  Union is never empty \n","        # hence it is safe to divide by its number of pixels\n","        intersection = np.sum(t * p)\n","        union = true + pred - intersection\n","        iou = intersection / union\n","        \n","        # iou metrric is a stepwise approximation of the real iou over 0.5\n","        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n","        \n","        metric += iou\n","        \n","    # teake the average over all images in batch\n","    metric /= batch_size\n","    return metric\n","\n","\n","def my_iou_metric(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n","\n","\n","# For Lovash loss\n","def my_iou_metric_2(label, pred):\n","    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6c12ETFA8t0","colab_type":"code","outputId":"80a5de03-1a42-4986-c385-f55e66d3c264","executionInfo":{"status":"error","timestamp":1569395277253,"user_tz":-540,"elapsed":1018,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["base_model = ResNet50(input_shape=input_size, include_top=False)\n","base_model.summary()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-7949462f9df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'input_size' is not defined"]}]},{"cell_type":"code","metadata":{"id":"fOFYXeG7A9CX","colab_type":"code","colab":{}},"source":["# Basic decoder block with Conv, BN and PReLU activation.\n","def decoder_block_simple(\n","        layer_name, block_name,\n","        num_filters=32,\n","        conv_dim=(3, 3)):\n","\n","    x_dec = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv'.format(block_name))(layer_name)\n","    x_dec = BatchNormalization(\n","        name='{}_bn'.format(block_name))(x_dec)\n","    x_dec = PReLU(\n","        name='{}_activation'.format(block_name))(x_dec)\n","\n","    return x_dec\n","\n","# Decoder block with bottleneck architecture, where middle conv layer\n","# is half the size of first and last, in order to compress representation.\n","# This type of architecture is supposed to retain most useful information.\n","def decoder_block_bottleneck(\n","        layer_name, block_name,\n","        num_filters=32,\n","        conv_dim=(3, 3),\n","        dropout_frac=0.2):\n","\n","    x_dec = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv1'.format(block_name))(layer_name)\n","    x_dec = BatchNormalization(\n","        name='{}_bn1'.format(block_name))(x_dec)\n","    x_dec = PReLU(\n","        name='{}_activation1'.format(block_name))(x_dec)\n","    x_dec = Dropout(dropout_frac)(x_dec)\n","\n","    x_dec2 = Conv2D(\n","        num_filters // 2, conv_dim,\n","        padding='same',\n","        name='{}_conv2'.format(block_name))(x_dec)\n","    x_dec2 = BatchNormalization(\n","        name='{}_bn2'.format(block_name))(x_dec2)\n","    x_dec2 = PReLU(\n","        name='{}_activation2'.format(block_name))(x_dec2)\n","    x_dec2 = Dropout(dropout_frac)(x_dec2)\n","\n","    x_dec2 = Conv2D(\n","        num_filters, conv_dim,\n","        padding='same',\n","        name='{}_conv3'.format(block_name))(x_dec2)\n","    x_dec2 = BatchNormalization(\n","        name='{}_bn3'.format(block_name))(x_dec2)\n","    x_dec2 = PReLU(\n","        name='{}_activation3'.format(block_name))(x_dec2)\n","    x_dec2 = Dropout(dropout_frac)(x_dec2)\n","\n","    x_dec2 = Add()([x_dec, x_dec2])\n","\n","    return x_dec2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v3pM6J-qBH2a","colab_type":"code","colab":{}},"source":["# Model is parametrized in a way to enable easy change of decoder_block type,\n","# as this is an argument that can be given a function, like decoder_block_simple.\n","def unet_resnet(input_size, decoder_block,\n","                weights='imagenet',\n","                loss_func='binary_crossentropy',\n","                metrics_list=[my_iou_metric],\n","                use_lovash=False):\n","\n","    # Base model - encoder\n","    base_model = ResNet50(\n","        input_shape=input_size, \n","        include_top=False,\n","        weights=weights)\n","    \n","    # Layers for feature extraction in the encoder part\n","    encoder1 = base_model.get_layer('activation_1').output\n","    encoder2 = base_model.get_layer('activation_10').output\n","    encoder3 = base_model.get_layer('activation_22').output\n","    encoder4 = base_model.get_layer('activation_40').output\n","    encoder5 = base_model.get_layer('activation_49').output\n","\n","    # Center block\n","    center = decoder_block(\n","        encoder5, 'center', num_filters=512)\n","    concat5 = concatenate([center, encoder5], axis=-1)\n","\n","    # Decoder part.\n","    # Every decoder block processed concatenated output from encoder and decoder part.\n","    # This creates skip connections.\n","    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n","    decoder4 = decoder_block(\n","        concat5, 'decoder4', num_filters=256)\n","    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n","\n","    decoder3 = decoder_block(\n","        concat4, 'decoder3', num_filters=128)\n","    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n","\n","    decoder2 = decoder_block(\n","        concat3, 'decoder2', num_filters=64)\n","    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n","\n","    decoder1 = decoder_block(\n","        concat2, 'decoder1', num_filters=64)\n","    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n","\n","    # Final upsampling and decoder block for segmentation.\n","    output = UpSampling2D()(concat1)\n","    output = decoder_block(\n","        output, 'decoder_output', num_filters=32)\n","    output = Conv2D(\n","        1, (1, 1), activation=None, name='prediction')(output)\n","    if not use_lovash:\n","        output = Activation('sigmoid')(output)\n","        \n","    model = Model(base_model.input, output)\n","    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9Y2j-KKBKTl","colab_type":"code","outputId":"eb326865-9223-447b-9459-f48efaa9b264","executionInfo":{"status":"ok","timestamp":1569395660564,"user_tz":-540,"elapsed":18805,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","input_size = (224, 224, 3)\n","\n","\n","K.clear_session()\n","model = unet_resnet(\n","    input_size, decoder_block_simple, weights='imagenet')\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94658560/94653016 [==============================] - 4s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From <ipython-input-10-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n","__________________________________________________________________________________________________\n","center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n","__________________________________________________________________________________________________\n","center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n","                                                                 activation_49[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n","                                                                 activation_40[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n","                                                                 activation_22[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n","__________________________________________________________________________________________________\n","decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n","__________________________________________________________________________________________________\n","prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n","==================================================================================================\n","Total params: 42,912,065\n","Trainable params: 42,856,833\n","Non-trainable params: 55,232\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MlAAE1BnBN4Q","colab_type":"code","outputId":"ea44037a-1fa9-4818-e822-972bce2a705c","executionInfo":{"status":"ok","timestamp":1569396273688,"user_tz":-540,"elapsed":606809,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["K.clear_session()\n","\n","# Build model:\n","# Here, you can experiment with various losses.\n","# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n","# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n","# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n","# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n","# This is controlled by use_lovash parameter.\n","model_depth = unet_resnet(\n","    input_size, decoder_block_bottleneck, weights='imagenet',\n","    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n","    use_lovash=False)\n","print(model_depth.summary())\n","\n","\n","model_checkpoint = ModelCheckpoint(\n","    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n","    save_best_only=True, save_weights_only=True, verbose=1)\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_my_iou_metric',\n","    mode='max',\n","    factor=0.5, \n","    patience=5, \n","    min_lr=0.0001, \n","    verbose=1)\n","\n","\n","epochs = 2  # 25\n","batch_size = 16\n","\n","history = model_depth.fit(X_tr, y_tr,\n","                    validation_data=[X_val, y_val], \n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    callbacks=[model_checkpoint,reduce_lr], \n","                    verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n","__________________________________________________________________________________________________\n","center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n","__________________________________________________________________________________________________\n","center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n","__________________________________________________________________________________________________\n","center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n","__________________________________________________________________________________________________\n","center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n","__________________________________________________________________________________________________\n","center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n","__________________________________________________________________________________________________\n","center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n","__________________________________________________________________________________________________\n","center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n","__________________________________________________________________________________________________\n","add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n","                                                                 dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n","                                                                 activation_49[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n","                                                                 dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n","                                                                 activation_40[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n","                                                                 dropout_9[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n","                                                                 activation_22[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n","__________________________________________________________________________________________________\n","decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n","__________________________________________________________________________________________________\n","decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n","                                                                 dropout_12[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n","                                                                 activation_10[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n","__________________________________________________________________________________________________\n","decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n","__________________________________________________________________________________________________\n","decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n","__________________________________________________________________________________________________\n","decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n","__________________________________________________________________________________________________\n","decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n","__________________________________________________________________________________________________\n","add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n","                                                                 dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n","__________________________________________________________________________________________________\n","decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n","__________________________________________________________________________________________________\n","decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n","__________________________________________________________________________________________________\n","decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n","__________________________________________________________________________________________________\n","decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n","__________________________________________________________________________________________________\n","add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n","==================================================================================================\n","Total params: 48,978,353\n","Trainable params: 48,919,953\n","Non-trainable params: 58,400\n","__________________________________________________________________________________________________\n","None\n","Train on 3196 samples, validate on 804 samples\n","Epoch 1/2\n","3196/3196 [==============================] - 276s 87ms/step - loss: 0.7406 - my_iou_metric: 0.3332 - val_loss: 4.9282 - val_my_iou_metric: 0.3887\n","\n","Epoch 00001: val_my_iou_metric improved from -inf to 0.38868, saving model to unet_resnet.h5\n","Epoch 2/2\n","3196/3196 [==============================] - 245s 77ms/step - loss: 0.5535 - my_iou_metric: 0.4789 - val_loss: 0.8483 - val_my_iou_metric: 0.1886\n","\n","Epoch 00002: val_my_iou_metric did not improve from 0.38868\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kk3i3LIrBQGT","colab_type":"code","colab":{}},"source":["val_preds = model_depth.predict(X_val, batch_size=16)\n","\n","y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n","y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7hkCKDWFBQ5e","colab_type":"code","colab":{}},"source":["# src: https://www.kaggle.com/aglotero/another-iou-metric\n","def iou_metric(y_true_in, y_pred_in, print_table=False):\n","    labels = y_true_in\n","    y_pred = y_pred_in\n","    \n","    true_objects = 2\n","    pred_objects = 2\n","\n","    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n","\n","    # Compute areas (needed for finding the union between all objects)\n","    area_true = np.histogram(labels, bins = true_objects)[0]\n","    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n","    area_true = np.expand_dims(area_true, -1)\n","    area_pred = np.expand_dims(area_pred, 0)\n","\n","    # Compute union\n","    union = area_true + area_pred - intersection\n","\n","    # Exclude background from the analysis\n","    intersection = intersection[1:,1:]\n","    union = union[1:,1:]\n","    union[union == 0] = 1e-9\n","\n","    # Compute the intersection over union\n","    iou = intersection / union\n","\n","    # Precision helper function\n","    def precision_at(threshold, iou):\n","        matches = iou > threshold\n","        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n","        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n","        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n","        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n","        return tp, fp, fn\n","\n","    # Loop over IoU thresholds\n","    prec = []\n","    if print_table:\n","        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        tp, fp, fn = precision_at(t, iou)\n","        if (tp + fp + fn) > 0:\n","            p = tp / (tp + fp + fn)\n","        else:\n","            p = 0\n","        if print_table:\n","            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n","        prec.append(p)\n","    \n","    if print_table:\n","        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n","    return np.mean(prec)\n","\n","def iou_metric_batch(y_true_in, y_pred_in):\n","    batch_size = y_true_in.shape[0]\n","    metric = []\n","    for batch in range(batch_size):\n","        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n","        metric.append(value)\n","    return np.mean(metric)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_apB6r0BTO7","colab_type":"code","outputId":"7aa75125-f601-4d34-b126-33c253d3a42e","executionInfo":{"status":"ok","timestamp":1569396353392,"user_tz":-540,"elapsed":45069,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Threshold range, over which optimization is performed\n","thresholds = np.arange(0.2, 0.9, 0.02)\n","\n","# For every threshold, set predictions to binary arrays, \n","# where values above threshold are treated as 1 and the rest as 0.\n","# Loop over thresholds and compute IoU for them based on IoU function above.\n","ious = np.array(\n","    [iou_metric_batch(y_val_true,\n","                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 35/35 [00:44<00:00,  1.25s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w9yAlPl5BVgK","colab_type":"code","outputId":"0111bc8f-29af-46b0-fd28-398b4a6ab03a","executionInfo":{"status":"ok","timestamp":1569396398083,"user_tz":-540,"elapsed":1028,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n","df_iou['iou'] = ious\n","\n","# Get index of best IoU\n","best_index = df_iou['iou'].idxmax()\n","print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n","    df_iou.iou[best_index], df_iou.threshold[best_index]))\n","\n","# Describe IoU DF\n","df_iou.describe()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Best IoU: 0.2863 at threshold: 0.880\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>threshold</th>\n","      <th>iou</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>35.000000</td>\n","      <td>35.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.540000</td>\n","      <td>0.201173</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.204939</td>\n","      <td>0.022213</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.200000</td>\n","      <td>0.190050</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.370000</td>\n","      <td>0.191107</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.540000</td>\n","      <td>0.192164</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.710000</td>\n","      <td>0.196455</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.880000</td>\n","      <td>0.286318</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       threshold        iou\n","count  35.000000  35.000000\n","mean    0.540000   0.201173\n","std     0.204939   0.022213\n","min     0.200000   0.190050\n","25%     0.370000   0.191107\n","50%     0.540000   0.192164\n","75%     0.710000   0.196455\n","max     0.880000   0.286318"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"Sa3thWZVBXoj","colab_type":"code","outputId":"43cb1c69-ece1-4dc4-ca86-78bc0ff2a86d","executionInfo":{"status":"ok","timestamp":1569397091110,"user_tz":-540,"elapsed":1436,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":572}},"source":["# Plot IoU values over threshold range.\n","df_iou.plot(x='threshold', y='iou')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fcbfe13c470>"]},"metadata":{"tags":[]},"execution_count":27},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 864x648 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"G_toQY9rBZjK","colab_type":"code","outputId":"8c61c730-7d11-4676-b736-6b727538ecc6","executionInfo":{"status":"error","timestamp":1569396683976,"user_tz":-540,"elapsed":1018,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["#plot.(y_val_pred)\n","\n","#random_index = np.random.randint(0, X_train.shape[0])\n","\n","#fig, ax = plt.subplots(1, 2)\n","\n","plt.imshow(X_test[0], cmap='gray')\n","#ax[1].imshow(y_train[random_index], cmap='gray')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-58918a58666e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#ax[1].imshow(y_train[random_index], cmap='gray')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"]}]},{"cell_type":"code","metadata":{"id":"sHcwvH6EW_Bq","colab_type":"code","outputId":"cb4b3cff-eaed-4f69-99c5-a7e7778538e1","executionInfo":{"status":"ok","timestamp":1569405618922,"user_tz":-540,"elapsed":8285811,"user":{"displayName":"Keiji Kakuta","photoUrl":"","userId":"01941455625997559853"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_test = np.asarray(\n","    [cv2.imread('/content/drive/My Drive/Sprint19/test_data/images/{}.png'.format(x), 0) for x in test.id.tolist()], \n","    dtype=np.uint8) / 255.\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(18000, 101, 101)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QK_PkJmxUeUO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkw2PiT7yX15","colab_type":"text"},"source":["### 【解答】\n","- 転移学習をさせるためにresnet50を最初に指定している\n","- weightsでImagenaetで学習した重みを使用している"]},{"cell_type":"markdown","metadata":{"id":"Ls51LjPRtQt9","colab_type":"text"},"source":["### 【問題2】コードの書き換え\n","エンコーダーにResNetが使用されていたコードをVGGに変更してください。"]},{"cell_type":"code","metadata":{"id":"by27M4D9vqLh","colab_type":"code","colab":{}},"source":["# エンコーダ部分をVGG19に変える\n","def unet_VGG(input_size, decoder_block,\n","                weights='imagenet',\n","                loss_func='binary_crossentropy',\n","                metrics_list=[my_iou_metric],\n","                use_lovash=False):\n","    \n","    # Encoder part\n","    # ベースモデルをVGG19に\n","    base_model = VGG19(\n","        input_shape=input_size, \n","        include_top=False,\n","        weights=weights)\n","    \n","    # プーリングの手前のレイヤのアウトプットをデコーダー部分でconcateするために保存\n","    encoder1 = base_model.get_layer('block1_conv2').output # (224,224,64)\n","    encoder2 = base_model.get_layer('block2_conv2').output # (112,112,228)\n","    encoder3 = base_model.get_layer('block3_conv4').output # (56,56,256)\n","    encoder4 = base_model.get_layer('block4_conv4').output # (28,28,512)\n","    encoder5 = base_model.get_layer('block5_conv4').output # (14,14,512)\n","\n","    # Center block\n","    center = decoder_block(\n","        encoder5, 'center', num_filters=512)\n","    concat5 = concatenate([center, encoder5], axis=-1) # (14,14,1024)\n","\n","    # Decoder part.\n","    decoder4 = decoder_block(\n","        concat5, 'decoder4', num_filters=256) #(14,14,256)　256個のフィルタで畳み込んでチャネルを減らす\n","    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1) #(28,28,256) + (28,28,512) = (28,28,768)\n","    # ↑(14,14,256)をアップサンプリングして，(28,28,256)にしてる．\n","    \n","    decoder3 = decoder_block(\n","        concat4, 'decoder3', num_filters=128) # (28,28,128)\n","    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1) # (56,56,,128) + (56,56,256)\n","\n","    decoder2 = decoder_block(\n","        concat3, 'decoder2', num_filters=64)\n","    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n","\n","    decoder1 = decoder_block(\n","        concat2, 'decoder1', num_filters=64)\n","    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n","\n","    # Final upsampling and decoder block for segmentation.\n","    #output = UpSampling2D()(concat1)\n","    #output = Conv2D(2, 32, activation = None, padding = 'same')(concat1)\n","    output = decoder_block(\n","        concat1, 'decoder_output', num_filters=32)\n","    output = Conv2D(\n","        1, (1, 1), activation=None, name='prediction')(output)\n","    if not use_lovash:\n","        output = Activation('sigmoid')(output)\n","        \n","    model = Model(base_model.input, output)\n","    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2W61QsT2tT3y","colab_type":"text"},"source":["### 【問題3】学習・推定\n","ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"]},{"cell_type":"markdown","metadata":{"id":"Ons0ELFwzwZf","colab_type":"text"},"source":["### VGG"]},{"cell_type":"code","metadata":{"id":"WyiW2XTmvyGP","colab_type":"code","colab":{}},"source":["K.clear_session()\n","\n","model_depth = unet_VGG(\n","    input_size, decoder_block_bottleneck, weights='imagenet',\n","    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n","    use_lovash=False)\n","print(model_depth.summary())\n","\n","\n","model_checkpoint = ModelCheckpoint(\n","    'unet_VGG.h5' ,monitor='val_my_iou_metric', mode='max',\n","    save_best_only=True, save_weights_only=True, verbose=1)\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_my_iou_metric',\n","    mode='max',\n","    factor=0.5, \n","    patience=5, \n","    min_lr=0.0001, \n","    verbose=1)\n","\n","epochs = 2  # 25\n","batch_size = 16\n","\n","history = model_depth.fit(X_tr, y_tr,\n","                    validation_data=[X_val, y_val], \n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    callbacks=[model_checkpoint,reduce_lr], \n","                    verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPvFKQnyv16J","colab_type":"code","colab":{}},"source":["val_preds = model_depth.predict(X_val, batch_size=16)\n","\n","y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n","y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aKbjsx8vv6vT","colab_type":"code","colab":{}},"source":["# src: https://www.kaggle.com/aglotero/another-iou-metric\n","#しきい値の最適化\n","def iou_metric(y_true_in, y_pred_in, print_table=False):\n","    labels = y_true_in\n","    y_pred = y_pred_in\n","    \n","    true_objects = 2\n","    pred_objects = 2\n","\n","    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n","\n","    # Compute areas (needed for finding the union between all objects)\n","    area_true = np.histogram(labels, bins = true_objects)[0]\n","    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n","    area_true = np.expand_dims(area_true, -1)\n","    area_pred = np.expand_dims(area_pred, 0)\n","\n","    # Compute union\n","    union = area_true + area_pred - intersection\n","\n","    # Exclude background from the analysis\n","    intersection = intersection[1:,1:]\n","    union = union[1:,1:]\n","    union[union == 0] = 1e-9\n","\n","    # Compute the intersection over union\n","    iou = intersection / union\n","\n","    # Precision helper function\n","    def precision_at(threshold, iou):\n","        matches = iou > threshold\n","        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n","        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n","        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n","        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n","        return tp, fp, fn\n","\n","    # Loop over IoU thresholds\n","    prec = []\n","    if print_table:\n","        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        tp, fp, fn = precision_at(t, iou)\n","        if (tp + fp + fn) > 0:\n","            p = tp / (tp + fp + fn)\n","        else:\n","            p = 0\n","        if print_table:\n","            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n","        prec.append(p)\n","    \n","    if print_table:\n","        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n","    return np.mean(prec)\n","\n","def iou_metric_batch(y_true_in, y_pred_in):\n","    batch_size = y_true_in.shape[0]\n","    metric = []\n","    for batch in range(batch_size):\n","        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n","        metric.append(value)\n","    return np.mean(metric)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7Lqfgarv9k-","colab_type":"code","colab":{}},"source":["# Threshold range, over which optimization is performed\n","thresholds = np.arange(0.2, 0.9, 0.02)\n","\n","# For every threshold, set predictions to binary arrays, \n","# where values above threshold are treated as 1 and the rest as 0.\n","# Loop over thresholds and compute IoU for them based on IoU function above.\n","ious = np.array(\n","    [iou_metric_batch(y_val_true,\n","                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2j3hOaTWv_xr","colab_type":"code","colab":{}},"source":["df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n","df_iou['iou'] = ious\n","\n","# Get index of best IoU\n","best_index = df_iou['iou'].idxmax()\n","print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n","    df_iou.iou[best_index], df_iou.threshold[best_index]))\n","\n","# Describe IoU DF\n","df_iou.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MG4oEF-4wCiM","colab_type":"code","colab":{}},"source":["# Plot IoU values over threshold range.\n","df_iou.plot(x='threshold', y='iou')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_rmn7TePwEnJ","colab_type":"text"},"source":["### Resnet"]},{"cell_type":"code","metadata":{"id":"ju32i-2AwJwz","colab_type":"code","colab":{}},"source":["# Model is parametrized in a way to enable easy change of decoder_block type,\n","# as this is an argument that can be given a function, like decoder_block_simple.\n","def unet_resnet(input_size, decoder_block,\n","                weights='imagenet',\n","                loss_func='binary_crossentropy',\n","                metrics_list=[my_iou_metric],\n","                use_lovash=False):\n","\n","    # Base model - encoder\n","    base_model = ResNet50(\n","        input_shape=input_size, \n","        include_top=False,\n","        weights=weights)\n","    \n","    # Layers for feature extraction in the encoder part\n","    encoder1 = base_model.get_layer('activation_1').output\n","    encoder2 = base_model.get_layer('activation_10').output\n","    encoder3 = base_model.get_layer('activation_22').output\n","    encoder4 = base_model.get_layer('activation_40').output\n","    encoder5 = base_model.get_layer('activation_49').output\n","\n","    # Center block\n","    center = decoder_block(\n","        encoder5, 'center', num_filters=512)\n","    concat5 = concatenate([center, encoder5], axis=-1)\n","\n","    # Decoder part.\n","    # Every decoder block processed concatenated output from encoder and decoder part.\n","    # This creates skip connections.\n","    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n","    decoder4 = decoder_block(\n","        concat5, 'decoder4', num_filters=256)\n","    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n","\n","    decoder3 = decoder_block(\n","        concat4, 'decoder3', num_filters=128)\n","    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n","\n","    decoder2 = decoder_block(\n","        concat3, 'decoder2', num_filters=64)\n","    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n","\n","    decoder1 = decoder_block(\n","        concat2, 'decoder1', num_filters=64)\n","    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n","\n","    # Final upsampling and decoder block for segmentation.\n","    output = UpSampling2D()(concat1)\n","    output = decoder_block(\n","        output, 'decoder_output', num_filters=32)\n","    output = Conv2D(\n","        1, (1, 1), activation=None, name='prediction')(output)\n","    if not use_lovash:\n","        output = Activation('sigmoid')(output)\n","        \n","    model = Model(base_model.input, output)\n","    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8A2NjdxAwNCf","colab_type":"code","colab":{}},"source":["# ResNetの層の確認\n","input_size = (224, 224, 3)\n","K.clear_session()\n","resnet_model = ResNet50(\n","        input_shape=input_size, \n","        include_top=False,\n","        weights='imagenet')\n","resnet_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5vlbv1xwQgs","colab_type":"code","colab":{}},"source":["input_size = (224, 224, 3)\n","\n","# U-Net ResNetのサマリーを見る\n","K.clear_session()\n","model = unet_resnet(\n","    input_size, decoder_block_simple, weights='imagenet')\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1JDa54uBwT3r","colab_type":"code","colab":{}},"source":["K.clear_session()\n","\n","# Build model:\n","# Here, you can experiment with various losses.\n","# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n","# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n","# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n","# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n","# This is controlled by use_lovash parameter.\n","model_depth = unet_resnet(\n","    input_size, decoder_block_bottleneck, weights='imagenet',\n","    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n","    use_lovash=False)\n","print(model_depth.summary())\n","\n","\n","model_checkpoint = ModelCheckpoint(\n","    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n","    save_best_only=True, save_weights_only=True, verbose=1)\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_my_iou_metric',\n","    mode='max',\n","    factor=0.5, \n","    patience=5, \n","    min_lr=0.0001, \n","    verbose=1)\n","\n","\n","epochs = 2  # 25\n","batch_size = 16\n","\n","history = model_depth.fit(X_tr, y_tr,\n","                    validation_data=[X_val, y_val], \n","                    epochs=epochs,\n","                    batch_size=batch_size,\n","                    callbacks=[model_checkpoint,reduce_lr], \n","                    verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oZx_IG5jwXXp","colab_type":"code","colab":{}},"source":["val_preds = model_depth.predict(X_val, batch_size=16)\n","\n","y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n","y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3QeSmrHWwaLv","colab_type":"code","colab":{}},"source":["# Threshold range, over which optimization is performed\n","thresholds = np.arange(0.2, 0.9, 0.02)\n","\n","# For every threshold, set predictions to binary arrays, \n","# where values above threshold are treated as 1 and the rest as 0.\n","# Loop over thresholds and compute IoU for them based on IoU function above.\n","ious = np.array(\n","    [iou_metric_batch(y_val_true,\n","                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqvmU852wcMf","colab_type":"code","colab":{}},"source":["df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n","df_iou['iou'] = ious\n","\n","# Get index of best IoU\n","best_index = df_iou['iou'].idxmax()\n","print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n","    df_iou.iou[best_index], df_iou.threshold[best_index]))\n","\n","# Describe IoU DF\n","df_iou.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-znFtL70weCs","colab_type":"code","colab":{}},"source":["# Plot IoU values over threshold range.\n","df_iou.plot(x='threshold', y='iou')"],"execution_count":0,"outputs":[]}]}