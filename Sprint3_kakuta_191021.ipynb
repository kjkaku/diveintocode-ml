{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint3 機械学習スクラッチ　線形回帰\n",
    "## 1.このSprintについて\n",
    "### Sprintの目的\n",
    "- スクラッチを通して線形回帰を理解する\n",
    "- オブジェクト指向を意識した実装に慣れる\n",
    "- 数式をコードに落とし込めるようにする\n",
    "\n",
    "### どのように学ぶか\n",
    "スクラッチで線形回帰を実装した後、学習と検証を行なっていきます。\n",
    "\n",
    "## 2.線形回帰スクラッチ\n",
    "線形回帰のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "以下に雛形を用意してあります。このScratchLinearRegressionクラスにコードを書き加えていってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雛形\n",
    "```\n",
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "        return\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ※解答はクラスのコードにまとめて入力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。   \n",
    "\n",
    "$$h\\theta(x) = \\theta_0x_0 + \\theta_1x_1 + ... + \\theta_jx_j + ... + \\theta_nx_n (x_0 = 1)$$\n",
    "\n",
    "$x$: 特徴量ベクトル\n",
    "\n",
    "$\\theta$: パラメータベクトル\n",
    "\n",
    "$n$: 特徴量の数\n",
    "\n",
    "$x_j$: j番目の特徴量\n",
    "\n",
    "$\\theta_j$: j番目のパラメータ（重み）\n",
    "\n",
    "特徴量の数\n",
    "n\n",
    "は任意の値に対応できる実装にしてください。\n",
    "\n",
    "なお、ベクトル形式で表すと以下のようになります。\n",
    "\n",
    "$$h\\theta(x) = \\theta^T \\cdot x.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雛形\n",
    "\n",
    "クラスの外から呼び出すことがないメソッドのため、Pythonの慣例としてアンダースコアを先頭にひとつつけています。\n",
    "```\n",
    "def _linear_hypothesis(self, X):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "    return\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h\\theta(x) = \\theta_0x_0 + \\theta_1x_1 + ... + \\theta_jx_j + ... + \\theta_nx_n (x_0 = 1)$$\n",
    "\n",
    "$x$: 特徴量ベクトル\n",
    "\n",
    "$\\theta$: パラメータベクトル\n",
    "\n",
    "$n$: 特徴量の数\n",
    "\n",
    "$x_j$: j番目の特徴量\n",
    "\n",
    "$\\theta_j$: j番目のパラメータ（重み）\n",
    "\n",
    "$$h\\theta(x) = \\theta^T \\cdot x.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m[(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}]$$\n",
    "\n",
    "\n",
    "$\\alpha$: 学習率\n",
    "\n",
    "$i$: サンプルのインデックス\n",
    "\n",
    "$j$: 特徴量のインデックス   \n",
    "   \n",
    "   \n",
    "   雛形\n",
    "\n",
    "ScratchLinearRegressionクラスへ以下のメソッドを追加してください。コメントアウト部分の説明も記述してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def _gradient_descent(self, X, error):\n",
    "    \"\"\"\n",
    "    説明を記述\n",
    "    \"\"\"\n",
    "    pass\n",
    "```\n",
    "雛形として用意されたメソッドや関数以外でも必要があれば各自作成して完成させてください。雛形を外れても問題ありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "仮定関数 \n",
    "$h\\theta(x)$ の出力が推定結果です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題4】平均二乗誤差\n",
    "線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成してください。\n",
    "\n",
    "平均二乗誤差関数は回帰問題全般で使える関数のため、ScratchLinearRegressionクラスのメソッドではなく、別の関数として作成してください。雛形を用意してあります。\n",
    "\n",
    "平均二乗誤差は以下の数式で表されます。\n",
    "\n",
    "$$L(\\theta) = \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)} - y^{(i)})^2$$\n",
    "\n",
    "$m$: 入力されるデータの数\n",
    "\n",
    "$h(\\theta)$: 仮定関数\n",
    "\n",
    "$x^{(i)}$: i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "$y^{(i)}$: i番目のサンプルの正解値\n",
    "\n",
    "なお、最急降下法のための目的関数（損失関数）としては、これを2で割ったものを使用します。（問題5, 9）\n",
    "\n",
    "雛形\n",
    "\n",
    "```\n",
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    pass\n",
    "    return mse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題5】目的関数\n",
    "以下の数式で表される線形回帰の **目的関数（損失関数）** を実装してください。そして、これを**self.loss**, **self.val_loss**に記録するようにしてください。\n",
    "\n",
    "目的関数（損失関数） $J(\\theta)$ は次の式です。\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)} - y^{(i)})^2$$\n",
    "\n",
    "$m$: 入力されるデータの数\n",
    "\n",
    "$h(\\theta)$: 仮定関数\n",
    "\n",
    "$x^{(i)}$: i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "$y^{(i)}$: i番目のサンプルの正解値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        self.coef = None\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "                    \n",
    "        \n",
    "        X_one = np.c_[np.ones(X.shape[0]), X]\n",
    "        X_val_one = np.c_[np.ones(X_val.shape[0]), X_val]\n",
    "        self.coef = np.ones(X_one.shape[1]) * 0.01\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            y_pred = self._linear_hypothesis(X_one)\n",
    "            y_val_pred = self._linear_hypothesis(X_val_one)\n",
    "            error = y_pred - y\n",
    "            val_error = y_val_pred - y_val\n",
    "            self.loss[i] = self._get_loss(y_pred, y)\n",
    "            self.val_loss[i] = self._get_loss(y_val_pred, y_val)\n",
    "            self._gradient_descent(X_one, error)        \n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print(self.loss)\n",
    "            print(self.val_loss)\n",
    "        \n",
    "        if self.bias:\n",
    "            print(\"theta\\n{}\".format(self.coef[1:]))\n",
    "            return self.coef[1:]\n",
    "        \n",
    "        else:\n",
    "            print(\"theta\\n{}\".format(self.coef))\n",
    "            return self.coef\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 問題3解答\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        X_one = np.c_[np.ones(X.shape[0]), X]\n",
    "        y_pred = self._linear_hypothesis(X_one)\n",
    "        return y_pred        \n",
    "    \n",
    "    def _linear_hypothesis(self, X):\n",
    "        # 問題1解答\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          学習データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        y_pred = np.dot(X, self.coef)\n",
    "        return y_pred\n",
    "    \n",
    "    def _gradient_descent(self, X, error):\n",
    "        # 問題2解答\n",
    "        \"\"\"\n",
    "        最急降下法による更新式\n",
    "        \"\"\"\n",
    "        self.coef = self.coef - (self.lr/np.shape(X)[0] * (np.dot(X.T, error)))\n",
    "        \n",
    "    def _get_loss(self, y_pred, y):\n",
    "        # 問題5解答\n",
    "        mse = 1/len(y) * sum((y_pred - y)**2)\n",
    "        loss = mse / 2\n",
    "        return loss\n",
    "    \n",
    "    def MSE(y_pred, y):\n",
    "        # 問題4解答\n",
    "        \"\"\"\n",
    "        平均二乗誤差の計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : 次の形のndarray, shape (n_samples,)\n",
    "          推定した値\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "          正解値\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        mse : numpy.float\n",
    "          平均二乗誤差\n",
    "        \"\"\"\n",
    "        mse = 1/len(y) * sum((y_pred - y)**2)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[0 0 0]\n",
      " [1 1 1]\n",
      " [2 2 2]\n",
      " [3 3 3]\n",
      " [4 4 4]]\n",
      "\n",
      "y\n",
      "[0 1 2 3 4]\n",
      "\n",
      "θ\n",
      "[0.01 0.01 0.01 0.01]\n",
      "\n",
      "one\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "\n",
      "Xone\n",
      "[[1. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 2. 2. 2.]\n",
      " [1. 3. 3. 3.]\n",
      " [1. 4. 4. 4.]]\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'coef'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3aae9f156d48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mXone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Xone\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtheta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_linear_hypothesis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-59bc8fcfd3a8>\u001b[0m in \u001b[0;36m_linear_hypothesis\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \"\"\"\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'coef'"
     ]
    }
   ],
   "source": [
    "X = np.array([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3], [4, 4, 4]])\n",
    "y = np.array([0, 1, 2, 3, 4])\n",
    "print(\"X\\n{}\\n\".format(X))\n",
    "print(\"y\\n{}\\n\".format(y))\n",
    "\n",
    "theta1 = np.ones(X.shape[1] + 1) * 0.01\n",
    "print(\"θ\\n{}\\n\".format(theta1))\n",
    "\n",
    "\n",
    "ones = np.ones((np.shape(X)[0], 1))\n",
    "print(\"one\\n{}\\n\".format(ones))\n",
    "Xone = np.c_[np.ones(X.shape[0]), X]\n",
    "print(\"Xone\\n{}\\n\".format(Xone))\n",
    "theta2 = _linear_hypothesis(Xone, theta1)\n",
    "print(theta2)\n",
    "error = theta2 - y\n",
    "print(error)\n",
    "theta3 = _gradient_descent(Xone, theta1, error)\n",
    "\n",
    "theta_x = np.dot(Xone, theta1)\n",
    "print(\"θx\\n{}\\n\".format(theta_x))\n",
    "lr = 0.1\n",
    "\n",
    "print(\"θx - y\\n{}\\n\".format(theta_x - y))\n",
    "\n",
    "print(\"(θx - y) * X\\n{}\\n\".format(np.dot((theta_x -  y), Xone)))\n",
    "\n",
    "theta_j = theta1 - lr/np.shape(X)[0] * (np.dot((theta_x - y), Xone))\n",
    "print(\"θj\\n{}\\n\".format(theta_j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta\n",
      "[0.32681544 0.32681544 0.32681544]\n",
      "y_pred\n",
      "[5.9535655  6.93401183]\n",
      "\n",
      "MSE\n",
      "0.0032553009827600123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3], [4, 4, 4], [5, 5, 5]])\n",
    "X_test = np.array([[6, 6, 6], [7, 7, 7]])\n",
    "y_train = np.array([0, 1, 2, 3, 4, 5])\n",
    "y_test = np.array([6, 7])\n",
    "\n",
    "iter = 100\n",
    "lr = 0.01\n",
    "bias = True\n",
    "verbose = False\n",
    "\n",
    "reg = ScratchLinearRegression(iter, lr, bias, verbose)\n",
    "reg.fit(X_train, y_train, X_test, y_test)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"y_pred\\n{}\\n\".format(y_pred))\n",
    "print(\"MSE\\n{}\\n\".format(MSE(y_pred, y_test)))\n",
    "#theta = fit(X_train, X_test, y_train, y_test, iter, lr)\n",
    "#y_pred = predict(X_test, theta)\n",
    "#mse = MSE(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.検証\n",
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題6】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_prices_data = pd.read_csv('train.csv') # HousePrices データセットを取得\n",
    "X = np.array(house_prices_data.loc[:, ['GrLivArea', 'YearBuilt']]) # 説明変数をX4に格納\n",
    "y = np.array(house_prices_data['SalePrice']) # 目的変数にy4に格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用、検証用データに分割する関数を定義\n",
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    assert isinstance(X, np.ndarray) and isinstance(y, np.ndarray), 'Xとyの型はndarrayにしてください' # X,yがndarray型でない場合はエラーを発生させる\n",
    "    assert X.shape[0] == len(y), 'Xの行数とyの列数がそろっていません。\\nXの列数：{} \\nyの行数：{}'.format(X.shape[0], len(y)) # X,yの行列数が合っていない場合ははエラーを発生させる\n",
    "    np.random.seed(0) # 再現性を保つためシードを固定\n",
    "    permutation = np.random.permutation(len(y)) # X, yをシャッフルする乱数を作成\n",
    "    x_shuffle = X[permutation] # Xをシャッフルさせる\n",
    "    y_shuffle = y[permutation] # yをシャッフルさせる\n",
    "    num = round(len(y) * train_size) # 分割点を取得\n",
    "    \n",
    "    X_train = x_shuffle[:][:num] # Xを分割しX_trainを作成\n",
    "    X_test = x_shuffle[:][num:] # 分割したXの残りでX_testを作成\n",
    "    y_train = y_shuffle[:num] # yを分割しy_trainを作成\n",
    "    y_test = y_shuffle[num:] # 分割したyの残りでy_testを作成\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = (X - np.mean(X)) / np.std(X)\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X_standard, y, train_size=0.8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta\n",
      "[13289.219024   57622.06507164]\n",
      "MSE\n",
      "5392299247.571175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter = 100\n",
    "lr = 0.01\n",
    "bias = True\n",
    "verbose = False\n",
    "\n",
    "reg = ScratchLinearRegression(iter, lr, bias, verbose)\n",
    "reg.fit(X_train, y_train, X_test, y_test)\n",
    "y_pred1 = reg.predict(X_test)\n",
    "print(\"MSE\\n{}\\n\".format(MSE(y_pred1, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Regression\n",
      "MSE : 2177514775.488449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"SGD Regression\"\n",
    "model = linear_model.SGDRegressor()\n",
    "model.fit(X_train, y_train) # 学習\n",
    "y_pred2 = model.predict(X_test) # 推定\n",
    "print(model_name)  \n",
    "print(\"MSE : {}\".format(mean_squared_error(y_test, y_pred2))) # 評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題7】学習曲線のプロット\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。\n",
    "\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAERCAYAAABowZDXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VfX9x/HXJ4uQkEnCDCEB2RvCHiIiggsHKOKioGjrqtZfq13WVlutrVU7VFBUHKgIKgqCFgXZEPbeBEKABMIMI+vz++NcNFLGBXLuvbn5PB+P+0juuSf5fu7jat6c812iqhhjjDHnEuLvAowxxlQMFhjGGGO8YoFhjDHGKxYYxhhjvGKBYYwxxisWGMYYY7wSdIEhImNEJFdEVnlxbi8RWSIixSIy6JTX7hKRjZ7HXe5VbIwxFUPQBQbwFtDfy3O3A8OA98seFJFE4EmgM9AJeFJEEsqvRGOMqXiCLjBU9Tsgv+wxEWkoIlNFZLGIzBKRpp5zt6nqCqD0lF9zJfC1quar6n7ga7wPIWOMCUph/i7AR0YB96nqRhHpDPwH6HOW8+sCO8o8z/YcM8aYSivoA0NEqgHdgPEicvJwlXP92GmO2RoqxphKLegDA+e22wFVbXseP5MN9C7zPAWYUY41GWNMhRN0fRinUtVDwFYRGQwgjjbn+LFpQD8RSfB0dvfzHDPGmEor6AJDRMYB84AmIpItIiOA24ARIrIcWA0M9JzbUUSygcHAayKyGkBV84E/AYs8jz96jhljTKUltry5McYYbwTdFYYxxhh3BFWnd1JSkqalpfm7DGOMqTAWL168V1WTvTk3qAIjLS2NzMxMf5dhjDEVhohkeXuu3ZIyxhjjFQsMY4wxXrHAMMYY4xULDGOMMV6xwDDGGOMVCwxjjDFescAwxhjjFdcCQ0Tqici3IrJWRFaLyMOnOUdE5GUR2SQiK0SkfZnXfLJFalFJKa/O3MzirP1uNWGMMUHBzSuMYuAXqtoM6ALcLyLNTzlnANDI8xgJvAK+3SK1sLiUt+du4zefrKSo5NSN94wxxpzkWmCo6i5VXeL5/jCwlv/dtW4gMFYd84F4EamND7dIja4SxlPXtWDd7sOMmb3VjSaMMSYo+KQPQ0TSgHbAglNeOtNWqF5vkSoiI0UkU0Qy8/LyLqi+fi1qcUXzmvzjvxvYkX/0gn6HMcYEO9cDw7NF6gTg557NjH708ml+RM9y/H8Pqo5S1QxVzUhO9mr9rNN66roWhIjw5KTV2JLvxhjzv1wNDBEJxwmL91R14mlOyQbqlXmeAuSc5bhr6sRX5dErGvPNulymrtrtZlPGGFMhuTlKSoA3gLWq+sIZTpsE3OkZLdUFOKiqu/DTFqnDuqXRok4sT05azcFjRW43Z4wxFYqbVxjdgTuAPiKyzPO4SkTuE5H7POdMAbYAm4DRwM/Af1ukhoWG8NxNrdlXUMizX65zuzljjKlQXNsPQ1Vnc/q+iLLnKHD/GV4bA4xxobSzalk3jhE90hn13RYGtq1DlwbVfV2CMcYEJJvpfRqP9G1MamIUT0xcyfGiEn+XY4wxAcEC4zSqRoTy5xtasXVvAS9P3+jvcowxJiBYYJxBj0ZJDOqQwmvfbWHVzoP+LscYY/zOAuMsfnd1c6pHR/DY+OUUFtuyIcaYys0C4yziosJ55oZWrNt9mFdmbPZ3OcYY41cWGOdwRfOaXNemDv/6diPrdp86Ud0YYyoPCwwv/OG6FsRGhvPY+OW2oq0xptKywPBCYnQET1/fklU7D/Gfb+3WlDGmcrLA8NKAVrW5rk0d/vnNRhs1ZYyplCwwzsMfB7YgwTNq6kSxTegzxlQuFhjnIT4qgmdvdEZNvfRfm9BnjKlcLDDO0+XNajK4Q4rtA26MqXQsMC7A769t7uyf8dEyCk4U+7scY4zxCQuMCxATGc7fB7dhe/5Rnp681t/lGGOMT1hgXKDODaozslcDxi3czvS1e/xdjjHGuM4C4yI8ekVjmtaK4VcTVpB3+IS/yzHGGFdZYFyEKmGhvDSkHYeOF/PLj5fj7AdljDHByQLjIjWpFcNvrmrGt+vzGDsvy9/lGGOMaywwysGdXetzWZNknpmylvW7D/u7HGOMcYVrgSEiY0QkV0RWneH1/xORZZ7HKhEpEZFEz2vbRGSl57VMt2osLyLC84PbEBsZxkPjltq2rsaYoOTmFcZbQP8zvaiqz6tqW1VtCzwBzFTV/DKnXOZ5PcPFGstNUrUq/G1wG9bvOcwzNtTWGBOEXAsMVf0OyD/niY5bgXFu1eIrvZvU4J6e6bwzP4upq3b5uxxjjClXfu/DEJEonCuRCWUOK/CViCwWkZHn+PmRIpIpIpl5eXluluqV/7uyKa1T4vjlxyvI3n/U3+UYY0y58XtgANcCc065HdVdVdsDA4D7RaTXmX5YVUepaoaqZiQnJ7td6zlFhIXwz1vbUarw8AfLbMMlY0zQCITAGMIpt6NUNcfzNRf4BOjkh7ouWP3q0fz5xlYsztrP37/a4O9yjDGmXPg1MEQkDrgU+KzMsWgRiTn5PdAPOO1Iq0B2XZs6DO2cyqszN/PNOls6xBhT8bk5rHYcMA9oIiLZIjJCRO4TkfvKnHYD8JWqFpQ5VhOYLSLLgYXAZFWd6ladAOQshcPl/0f999c0p3ntWB79aDk7Dxwr999vjDG+JMG0nEVGRoZmZp7ntI1j++GFFnDJ5XDLO+Ve07a9BVzzz9k0qlmND0d2JSIsEO4CGmOMQ0QWezt9wf56VU2AXo/B2kmw+tNy//VpSdE8d1Nrlm4/wF++tPkZxpiKywIDoNtDULstTP4FFOwr919/devaDO+ezptztjFpeU65/35jjPEFCwyA0DC4/j9w/CBM/ZUrTTxxVVMy6ifw+IQVbNxj600ZYyoeC4yTarZwbk2tHA/rJpf7rw8PDeFfQ9sTFRHKfe8u5oht7WqMqWAsMMrq8SjUbAmf/xyOeruqifdqxUXy8q3t2Lq3gMc+sv0zjDEViwVGWWERcP0rcCwfpjzmShPdGibxxIBmTF29m//M2OxKG8YY4wYLjFPVbg2XPg6rJsDqT1xp4u6e6Vzbpg5/+2o9Mzf4f/0rY4zxhgXG6fR4BOq0hy8ehSO55f7rRYTnbmpFk5oxPDRuKVn7Cs79Q8YY42cWGKcTGgY3vAqFBfD5w+BCX0NURBiv3dEBgHvGZlonuDEm4FlgnElyE7j897B+Ciwt/xng4CxS+O+h7dmcV8CjHy6jtNQ6wY0xgcsC42y6/AzSe8GXj0P+Flea6NEoid9c1Yyv1uzhxekbXWnDGGPKgwXG2YSEOKOmQsNg4r1Q4s5to590T2NwhxRenr6RyStspz5jTGCywDiXuBS4+gXIXgiz/+FKEyLC0ze0pEP9BH4xfhkrsg+40o4xxlwMCwxvtBoErQbDjL/AjkWuNFElLJTX7uhA9egq3DM2k90Hj7vSjjHGXCgLDG9d/XeIqwsTRsDxQ640kVStCm8My+DI8WLuHruIo4U2csoYEzgsMLwVGQc3vg4Hd7g2Cxygaa1Y/jm0HatzDvHIh8sosZFTxpgAYYFxPlI7O7PAV3wIyz90rZk+TWvyu6ubM231Hp61PTSMMQHCAuN89fwFpHaFyY/CPvfWghreI51h3dIYPWsr78zPcq0dY4zxlgXG+QoNg5teh9BwGD8Mik+41tTvrmnO5U1r8ORnq/h2ffkvUWKMMefDtcAQkTEikisiq87wem8ROSgiyzyP35d5rb+IrBeRTSLyuFs1XrC4FGd+xu4V8NXvXGsmNER4+dZ2NKsdy/3vLWFl9kHX2jLGmHNx8wrjLaD/Oc6ZpaptPY8/AohIKPBvYADQHLhVRJq7WOeFaTLAmQm+8DVY+7lrzURXCePNYR1JiIrgJ28tYkf+UdfaMsaYs3EtMFT1O+BCdiHqBGxS1S2qWgh8AAws1+LKS9+noE47+PR+2L/NtWZqxEby9vCOFJWUctebC9lfUOhaW8YYcyb+7sPoKiLLReRLEWnhOVYX2FHmnGzPscATFgGD3wIBProTitybbHdJjRhevyuD7P3HGPH2Io4VlrjWljHGnI4/A2MJUF9V2wD/BD71HJfTnHvGyQgiMlJEMkUkMy/PD5sRJaTB9a/CruUw7QlXm+qYlshLt7Rl6Y4DPPD+EopLSl1tzxhjyvJbYKjqIVU94vl+ChAuIkk4VxT1ypyaAuSc5feMUtUMVc1ITk52teYzanoVdH8YMsfAivGuNjWgVW3+NLAl09fl8sTElbYvuDHGZ8L81bCI1AL2qKqKSCec8NoHHAAaiUg6sBMYAgz1V51e6/N7Z52pzx+Cmi2gpnv99Ld3qU/u4RO8PH0j1atV4fEBTV1ryxhjTnJzWO04YB7QRESyRWSEiNwnIvd5ThkErBKR5cDLwBB1FAMPANOAtcBHqrrarTrLTWgYDH4TqsTAh7fDcXeHwD7StxFDO6fy6szNvDbTvQmExhhzkgTTLY2MjAzNzMz0bxFZ8+Dta6DRlXDLu86eGi4pKVUe/mApX6zYxbM3tmJIp1TX2jLGBCcRWayqGd6c6+9RUsGnflfo9wysnwyzX3C1qdAQ4YWb23Jp42R+/clKpqy0zZeMMe6xwHBD53uh1c3wzdOw4StXm4oIC+HV2zvQPjWBhz9YyrfrbAkRY4w7LDDcIALXvgS1WsKEu2HvJlebqxoRypifdKRJrRjue3cxczfvdbU9Y0zlZIHhlogoGPK+0xn+wa2ud4LHRoYzdnhn6leP4u63M1mctd/V9owxlY8FhpviU2Hw284y6BNHQqm7s7MToyN4d0RnasRUYdibC21vcGNMubLAcFt6TxjwHGyYCtP/6HpzNWIjee+eLsRVDeeONxayaqetcGuMKR8WGL7Q8W7IGA5zXoRl41xvrm58Vcbd04XoiFDueGMB63a7swe5MaZyscDwBREY8FdI7+XMBN++wPUm6yVGMW5kFyLCQrht9ALW7z7sepvGmOBmgeEroeFOf0ZcCnwwFPa7v+1q/erRjLunC2GhwtDR8y00jDEXxQLDl6ISYehHUFoE798Mx9zvlG6QXI0PRnYlLFS4dfR8uz1ljLlgFhi+ltTIWTJk3yYYfxeUFLneZHpSNB+M7EpEaAi3jprP6hzrCDfGnD8LDH9I7wXXvgxbZsDkR8EH63k5odGFquGhDB29gOU7bMitMeb8WGD4S7vboOdjsGSs62tOnZSWFM2H93YltmoYt7++gMVZF7KDrjGmsrLA8KfLfgOtBjvzM5Z/6JMm6yVG8eHIriTFVOGONxYyd5MtI2KM8Y4Fhj+FhMDAf0NaT/jsfucWlQ/Uia/KhyO7kJJQlWFvLWL62j0+adcYU7FZYPhbWBWnE7z6JfDhHbB7pU+arREbyYcju9K0Vgz3vrOYz5efcRdcY4wBLDACQ9V4uP1jiKgG794E+7f5pNmE6Ajeu7sz7VMTeOiDpby/YLtP2jXGVEwWGIEiLgXumAjFJ+CdG+BInk+ajYkM5+3hnejt2YTp399uIph2YTTGlB8LjEBSo5kzse/QLnhvEJzwzczsqhGhjLozg+vb1uH5aev585S1lJZaaBhjfswCI9Ckdoab33b6Mj4YCkXHfdJseGgIL9zclmHd0hg9ayuPjV9OUUmpT9o2xlQMrgWGiIwRkVwRWXWG128TkRWex1wRaVPmtW0islJElolIpls1BqzGV8L1r8DW7+Dj4VBS7JNmQ0KEJ69tzmP9GjNx6U5GvJ1JwQnftG2MCXxuXmG8BfQ/y+tbgUtVtTXwJ2DUKa9fpqptVTXDpfoCW5tbYMDzsH6yM+S21Df/2hcRHujTiOduasXsjXncOno+e4+c8EnbxpjA5lpgqOp3wBmnEqvqXFU9uY/ofCDFrVoqrM4j4bLfwooP4Mtf+mQJkZNu6ZjKqDsy2LDnMDf+Zy5b8o74rG1jTGAKlD6MEcCXZZ4r8JWILBaRkWf7QREZKSKZIpKZl+ebkUU+1esx6PYgLBoNX//Op6HRt3lNxt3ThSMnirnplbm2lIgxlZzfA0NELsMJjF+VOdxdVdsDA4D7RaTXmX5eVUepaoaqZiQnJ7tcrR+IwBV/go73wNx/woxnfdp8u9QEJv60G3FVwxk6egFTVu7yafvGmMDh18AQkdbA68BAVd138riq5ni+5gKfAJ38U2GAOLljX7vbYeazMOvvPm0+LSmaiT/rTos6sfzsvSW8OnOzzdUwphLyW2CISCowEbhDVTeUOR4tIjEnvwf6AacdaVWphIQ4S6KfXKxwzks+bT4xOoL37+nCNa1r8+yX63hi4kobdmtMJRPm1i8WkXFAbyBJRLKBJ4FwAFV9Ffg9UB34j4gAFHtGRNUEPvEcCwPeV9WpbtVZoYSEwvWvgpbC178HCXH6N3wkMjyUl4e0I616NP/6dhPb84/yn9vaEx8V4bMajDH+I8F0ayEjI0MzMyvBtI2SYph4N6z+BPo9A90e8HkJExZn88TEldRNqMobd2XQILmaz2swxlw8EVns7fQFr25JicjDIhIrjjdEZImI9Lu4Ms0FCw2DG0dD84Hw1W98fnsK4KYOKbx/T2cOHSvi+n/PYfZG21fDmGDnbR/GcFU9hNOfkAz8BPDtcB3zY6HhcNMb0OJG5/aUjzvCATLSEvn0/u7UjqvKnWMW8MbsrdYZbkwQ8zYwxPP1KuBNVV1e5pjxl9Bw50qj1c1OR/iM53w6TwOcHfwm/qwbVzSvyZ++WMNj41dwvKjEpzUYY3zD28BYLCJf4QTGNM8oJhsiEwhCw+CGV6HNUJjxZ/jvH3weGtFVwnjltg48fHkjJizJ5pZR89l18JhPazDGuM/bwBgBPA50VNWjOKOdfuJaVeb8hIQ6W71mjIA5LzrLiPho7anvSwgRHrmiMa/e3oFNew5z7T9ns3CrzQw3Jph4GxhdgfWqekBEbgd+Cxx0ryxz3kJC4Oq/O8NsF46CSQ/4bJXbsvq3rMVnD3QnNjKcoaPn89Yc69cwJlh4GxivAEc9S5D/EsgCxrpWlbkwJ5cR6f1rWPYejL/LZ/tplHVJjRg+faA7vZvU4A+fr+HhD5ZxtNCWSTemovM2MIrV+WfiQOAlVX0JiHGvLHPBRKD3r6D/c7DuC3h/sM927isrNjKcUXd04P+ubMIXK3K4/t9z2Gwr3hpToXkbGIdF5AngDmCyiITimbVtAlSX++CG12DbHHj7Oijw/TyJkBDh/ssuYezwzuw9Ush1/5zN58tzfF6HMaZ8eBsYtwAncOZj7AbqAs+7VpUpH22GwJD3IHcNvNEP9m/zSxk9GiXxxYM9aFo7lgfHLeX3n63iRLENvTWmovEqMDwh8R4QJyLXAMdV1fowKoImA+DOz+DoPic0dq/0Sxl14qvywcgu3NMznbHzshj0yjyy9hX4pRZjzIXxdmmQm4GFwGDgZmCBiAxyszBTjlK7wPCpEBIGYwbA5m/9UkZ4aAi/ubo5o+7oQNa+Aq5+eTaT7BaVMRWGt7ekfoMzB+MuVb0TZ3+K37lXlil3NZrBiK8gvh68NwiWjfNbKf1a1GLKwz1pXLMaD41byhMTV3Cs0G5RGRPovA2MEM9mRiftO4+fNYEiLgV+8iXU7waf3gczn/f5rPCTUhKi+PDervy0d0PGLdzBtf+azZqcQ36pxRjjHW//6E8VkWkiMkxEhgGTgSnulWVcUzUebpsArYfAt0/DZ/dDcaFfSgkPDeFX/Zvy7ogfVr190yb6GROwvN4PQ0RuArrjLDr4nap+4mZhF6LS7IdRHlSd/cFnPgtpPeHmsRCV6Ldy9h05wS8/XsH0dbn0apzM3wa1pkZspN/qMaayOJ/9MGwDpcpuxUfOVUZ8Kgz9CKo39Fspqsq7C7bzzOQ1REWE8ZcbW3Fli1p+q8eYyqDcNlASkcMicug0j8MiYjecg0Hrmz3DbvNhdB/YMsNvpYgId3SpzxcP9qROfCT3vrOY/xu/nMPHi/xWkzHmB2cNDFWNUdXY0zxiVDXWV0Ual9XvBiO/hZja8M6NsHC0X8u5pEY1Jv60Ow9cdgkTlmTT/8VZzNu8z681GWNcHukkImNEJFdEVp3hdRGRl0Vkk4isEJH2ZV67S0Q2eh53uVmnARLSnGG3l/SFKY/B5z/3W2c4QERYCI9d2YSPf9qN8FDh1tHzeerz1Tb81hg/cnto7FtA/7O8PgBo5HmMxFkVFxFJBJ4EOuPM+XhSRBJcrdRAZCzcOg56PAKL34Sx18GR3HP/nIvapyYw5eGe3NW1Pm/O2cZVL89icZbts2GMP7gaGKr6HXC2/7sHAmPVMR+IF5HawJXA16qar6r7ga85e/CY8hISCn3/4OwXnrMMRvWG7MV+LSkqIoynBrbk/Xs6U1RSyqBX5/GnL9bY1YYxPubvyXd1gR1lnmd7jp3p+P8QkZEikikimXl5ea4VWum0GuTcopJQeLM/LH7L3xXRrWESU3/ei9s6p/LG7K30f+k75m+xvg1jfMXfgSGnOaZnOf6/B1VHqWqGqmYkJyeXa3GVXu3WcO9MqN8dPn8YJj3olw2ZyqpWJYynr2/FuHu6oApDRs3n15+s5JCNpDLGdf4OjGygXpnnKUDOWY4bX4tKhNsnQI9HYclYGHOl35ZJL6trw+pM/XlP7u6RzgcLt3PFCzP5avVuf5dlTFDzd2BMAu70jJbqAhxU1V3ANKCfiCR4Orv7eY4ZfwgJhb5PwpD3IX8rvNYL1n/p76qIigjjt9c055OfdSchKoKR7yzmp+8uZvdB/14FGROs3B5WOw6YBzQRkWwRGSEi94nIfZ5TpgBbgE3AaOBnAKqaD/wJWOR5/NFzzPhT06udW1Tx9WHcEPjqd1Di/1tBberF8/mDPfhl/yZ8sy6Xvi/M5O252ygpDZ5VDIwJBLY0iDl/Rcdh6uPO0NuUTjBojLNsegDI2lfAbz9dxayNe2mTEsfT17eiVUqcv8syJmCV29IgxpxWeCRc+6ITFLlr4dUesG6yv6sCoH71aMYO78RLQ9qSc/A4A/89myc/W2Wd4saUAwsMc+Fa3uTcokqoDx8MhcmPQdExf1eFiDCwbV2m/+JS7uhSn3fmZ9HnbzOZsDjblk435iJYYJiLU70hjPgauj4Ai0Y7CxjmrvV3VQDERobz1MCWTHqgB/USq/KL8csZ/Oo8Vucc9HdpxlRIFhjm4oVVgSufcTZmKshzZocveM1vu/mdqmXdOCbc142/DmrN1r0FXPvP2fzmk5XkF/hvrSxjKiLr9Dbl60gufPYAbJwGDS+H6/8DMYGzp8XBY0W8+N8NjJ2XRXREKI9c0Zjbu9QnPNT+7WQqJ9tAyfiXKmS+AdN+63SQX/MPaHGDv6v6kQ17DvPU56uZs2kfl9Soxm+vbkbvJjX8XZYxPmejpIx/iUDHu+He7yAhHcYPgwl3w7H9/q7se41rxvDuiM6MvjOD4pJShr25iLvGLGTDnsP+Ls2YgGVXGMZdJUUw6wWY+RxUqwHXvgyN+/m7qh85UVzC2LlZvPzNRgpOFHNLx1QevaIxyTFV/F2aMa6zW1Im8OQshU9+Cnlroe3tTid51Xh/V/Uj+wsKeWn6Rt6dn0WVsBBG9mrI3T3Tia4S5u/SjHGNBYYJTMUnYMazMOdFqFbL6dtoEnjbnGzdW8Dz09YxZeVukmOq8PO+jbg5o551jJugZIFhAtvOxc5Iqtw10Gow9H8Ooqv7u6r/sThrP89+uZZF2/aTnhTNL/o15qqWtQkJOd3q+8ZUTBYYJvAVF8KsvzuPyFi48i/Q+manwzyAqCrT1+by12nr2LDnCC3rxvJYvyZc2jgZCbBajbkQFhim4tizGiY9BDsznXkb17wACWn+rup/lJQqnyzdyYv/3UD2/mN0SkvksSub0Ck90d+lGXNRLDBMxVJaAovegOlPOd/3/pWz1EhouL8r+x+FxaV8uGg7L3+zibzDJ+jZKIlHrmhM+9QEf5dmzAWxwDAV08Fs+PJXsO4LSG7mdIrX7+rvqk7rWGEJ787P4pWZm8kvKOSyJsn8vG9j2tQLrJFfxpyLBYap2NZNgS9/CQd3QNvboO9TUC0w92svOFHM2/O2Meq7LRw4WsRlTZJ5uG9j2lpwmArCAsNUfIUF8N3zMPdfEB4FfX4LGcMhNDDnRBw5Uczbc7cxepYTHL0aJ/NQn0vISLM+DhPYLDBM8MjbAFMeg60zoWZLGPAcpPXwd1VndOREMWPnbeONWVvZV1BIlwaJPNinEd0aVrdRVSYgWWCY4KIKaz6Dr37r3KZqcSNc8ceA2Rb2dI4WFjNu4Q5em7mZ3MMnaFMvnvt7N6Rvs5o2j8MEFAsME5wKj8Kcl5yZ4gh0fwi6PwwR0f6u7IxOFJcwYfFOXp25me35R2lUoxojezVgYNu6RITZzHHjfwETGCLSH3gJCAVeV9VnT3n9H8BlnqdRQA1Vjfe8VgKs9Ly2XVWvO1d7FhiVxIEd8N8nYdUEiKkDl/8OWg+BkMD9A1xcUsrklbt4ZcZm1u0+TO24SIZ3T2dIp3rERAbe8GFTeQREYIhIKLABuALIBhYBt6rqmjOc/yDQTlWHe54fUdVq59OmBUYls30+TH0CcpZArdbOgobpvfxd1VmpKjM25PHqjM0s2JpPTJUwhnZJZVi3NGrHVfV3eaYSCpTA6Ar8QVWv9Dx/AkBV/3KG8+cCT6rq157nFhjm3EpLnSuN6U85/RuN+kHfP0DNFv6u7JyW7zjAqFlb+HLlLkJEuLZNHUb0SKdl3Th/l2YqkUAJjEFAf1W92/P8DqCzqj5wmnPrA/OBFFUt8RwrBpYBxcCzqvrpGdoZCYwESE1N7ZCVleXG2zGBrug4LHjV2XvjxCFoOxQu+zXEpfi7snPakX+UN+ds48NF2ykoLKFzeiLDe6TTt1lNQq2D3LgsUAJjMHDlKYHRSVUfPM25v8IJiwfLHKujqjki0gD4BrhcVTefrU27wjAczXcWNFw4ChDodA/0eDQgV8M91aHjRXywcDtvz81i54Fj1Eusyl1d0xicUY+4qtbPYdwRKIHh9S0pEVkK3K+qc8/wu94CvlDVj8/WpgWG+d6BHTDzWVj2PoRHQ9f7oev3z1pPAAAVR0lEQVTPIDLwb/cUl5Ty9Zo9jJmzlUXb9lM1PJQb2tdlWLc0GteM8Xd5JsgESmCE4XR6Xw7sxOn0Hqqqq085rwkwDUhXTzEikgAcVdUTIpIEzAMGnqnD/CQLDPM/8tbDN0/D2kkQGe8Mw+18b0APxS1r1c6DjJ23jU+X5VBYXErn9ETu6FqfK1vUsg2dTLkIiMDwFHIV8CLOsNoxqvqMiPwRyFTVSZ5z/gBEqurjZX6uG/AaUAqEAC+q6hvnas8Cw5xRzjL49s+wcRpEJTnB0fFuiIjyd2VeyS8o5KPMHbw7P4vs/ceoEVOFIR3rMaRTKnXibXSVuXABExi+ZoFhzmnHQpjxF9j8DUQnO8GRMbzCXHGUlCoz1ufy7vwsZmzIQ4A+TWswtHMqlzauYZ3k5rxZYBhzLtvnO8GxZQZEVXf23+h0D1SpOH0EO/KPMm7hdj7KzGbvkRPUiYvk5o71GJxRj7p21WG8ZIFhjLd2LISZf4VNXzsd4p3vcx5RFWeV2aKSUv67Zg/vL9zO7E17Abi0cTJDOtajT9OatgSJOSsLDGPO184lznDcdV84o6oyfuKMrIqt4+/KzsuO/KOMz9zBR5nZ7D50nMToCK5vW5ebO6bQtFasv8szAcgCw5gLlbvWmfy3agJICLS+xennSG7s78rOS3FJKbM27WV85g6+XrOHohKlVd04BnVI4bo2dUiIjvB3iSZAWGAYc7H2Z8G8f8GSd6D4GDQeAN0ehPrdoILta7HvyAkmLc/h48XZrM45RHio0KdpDW5sn8JlTWrYLatKzgLDmPJSsBcWjnZmjh/LhzrtnVtVzQdCaMWbfb0m5xATlmTz2bIc9h45QXxUONe0rs0N7erSPjXBNnmqhCwwjClvhUdh2Xsw/xXI3wyxKdB5JLS/E6om+Lu683byltXEJTv5es1ujheVUi+xKgPb1GVg2zo0shnllYYFhjFuKS11Jv/N+zdsm+XsN95miDOyKrmJv6u7IEdOFDNt1W4+XbaTOZv2UqrQtFYM17Wtw7Wt61AvsWJMbjQXxgLDGF/YvdJZIXfFeCg5AemXQqeR0Lg/hIb5u7oLknf4BJNX5PDZ8hyWbj8AQNt68VzTujZXtapts8qDkAWGMb5UsBeWvA2LxsChbIirBx2GOberqtXwd3UXbEf+USav3MWkZTms2XUIgIz6CVzVqjYDWtWyDZ+ChAWGMf5QUgwbvnQ6yLd+ByHh0Pw6Z+mR+t0r3OiqsrbuLWDyihy+WLGLdbsPA9A+NZ4BLWvTv2Utu21VgVlgGONveRsgcwwsfx+OH4TqjZyrjja3Voi9Oc5mS94Rvly1mykrd7E6x7nyaFEnlv4tanFly1o0qlHNRltVIBYYxgSKwqOw5lPIfBOyF0JoBDS9xrldlX4phFTsORDb9x1l6updfLlq9/d9HulJ0fRrXpMrmtekXWqCLYgY4CwwjAlEe9bAkrGwfBwcPwBxqdDuNmc72fhUf1d30fYcOs5Xa/bw1erdzNu8j+JSJalaBH2a1qBvs5r0aJREVETFHAwQzCwwjAlkRcedNauWvuuslguQ3hPa3gbNrq0wS62fzaHjRcxYn8fXa/YwY30uh48XUyUshG4Nq3N5s5r0aVrDRlwFCAsMYyqKA9th2Tinr2P/Noio5swibzME6veo8LeswFlNd9HWfL5eu4fpa3PZnn8UgGa1Y7msSTKXNa1Bu3rxhNkOgn5hgWFMRaMK2+c5s8lXfwaFh53Z5K0GQeuboWYLf1dYLlSVzXkFTF+7h2/W5ZKZtZ+SUiWuajg9GiXRu3EylzZJpkZMpL9LrTQsMIypyAqPwvopsOJD2DQdtARqtHDCo+VNkFDf3xWWm4PHipizaS/frstl5oY8cg+fAKB57Vh6NU6mV+MkMuon2gKJLrLAMCZYFOyF1Z844ZG9yDmW0skJjhbXQ0wt/9ZXjlSVNbsOMXNDHt9tyCNz236KS5WoiFC6NKhOj0uS6NkoiUts2G65CpjAEJH+wEtAKPC6qj57yuvDgOeBnZ5D/1LV1z2v3QX81nP8aVV9+1ztWWCYoLZ/m7NPx8oJkLsaEGdCYMsboNl1FXpW+ekcOVHMvM37mL0xj1kb97JlbwEANWOr0P2SJLo3TKL7JUnUirPbVxcjIAJDREKBDcAVQDawCLhVVdeUOWcYkKGqD5zys4lAJpABKLAY6KCq+8/WpgWGqTRy1zlXHqsnwt4NfB8ezQdCs2sq3E6B3tiRf5S5m/cya+Ne5m7eR35BIQANkqPp3jCJrg2r06VBdRJtc6jzEiiB0RX4g6pe6Xn+BICq/qXMOcM4fWDcCvRW1Xs9z18DZqjquLO1aYFhKh1VZ5fANZ85EwTz1jnHUzo5Q3SbXQOJDfxbowtKS5W1uw8xd9M+5mzey6Kt+RQUlgDOSrtdGjjh0Tk90XYXPIdACYxBQH9Vvdvz/A6gc9lw8ATGX4A8nKuRR1R1h4g8BkSq6tOe834HHFPVv52mnZHASIDU1NQOWVlZrrwfYyqEvPWwZhKs/cxZTRecDvNm10CTAVC7bYVe0+pMikpKWZF9kHmb9zJ/Sz6ZWfkcLyoFnADpnJ5I5wbV6ZiWSHJMFT9XG1gCJTAGA1eeEhidVPXBMudUB46o6gkRuQ+4WVX7iMj/AVVOCYyjqvr3s7VpVxjGlLF/G6yb4kwS3D4PtBRi6zrB0XiAM1kwLDj/eBYWl7I8+wALtuxjwdZ8Mrft51iRcwXSICmajmmJdExPpFNaIvUSq1bqTvRACYxz3pI65fxQIF9V4+yWlDHlrGAvbJjmDNfd/A0UHYXwaGh4mbN/R6N+EFPT31W6pqiklFU7D7JoWz4LtuSTmbWfg8eKAKgRU4WMtAQ61E8ko34CzevEEl6JJhEGSmCE4dxmuhxnFNQiYKiqri5zTm1V3eX5/gbgV6raxdPpvRho7zl1CU6nd/7Z2rTAMMYLRcdg6yxnKfb1U+FwjnO8dlsnOBr1g7rtISTUv3W6qLRU2Zh7hIXb8snc5lyB7DxwDIDI8BDapMTToX4C7VMTaJcaT/VqwXklBgESGJ5CrgJexBlWO0ZVnxGRPwKZqjpJRP4CXAcUA/nAT1V1nednhwO/9vyqZ1T1zXO1Z4FhzHlShT2rnKuPjV85cz20FKomQsM+cElf52sQX32ctOvgMRZn7Wdx1n6WZO1ndc4hikudv49p1aNoWy+edqkJtK0XT7PasUEzmTBgAsPXLDCMuUhH851bVhu/hs3ToSDPOV6rlRMcDftAvS4QHvxzH44XlbAi+yBLtjsBsnTHAfI8M9EjwkJoUSeWtvXiaVsvntYp8aRVj6qQfSEWGMaYi1daCntWwqb/wuZvYft8KC2CsEhI7QoNejuPWq2DYpHEc1FVcg4eZ+n2/SzfcYDlOw6yYueB70djxVUNp1XdOFqnxNE6JZ7WKXHUjosM+BCxwDDGlL8TRyBrjhMeW2ZA3lrneNUESOsJDS6FtF6Q1Cgoh+6eTnFJKRtzjzgBkn2AFdkHWb/78Pe3sqpHR9Cybhyt6sbRsm4cLevGUjc+sEZlWWAYY9x3aJezd/nWmbBlJhzKdo5XqwVpPTyPnlC9YaUJEHBuZa3ZdYhVOw+yMvsgK3ceZGPuEUo8IRIfFU6LOrG0rBNH8zqxtKgTS3pSNb/tTGiBYYzxLVXI3wLbZjkjsLbNhiO7ndeq1YL63TyP7pDctFLcwirreFEJaz0hsjrnEKtzDrF+92EKS5zbWVXDQ2lSK4bmdWJpXjuWZrVjaVIrhmpV3N+h0ALDGONfqrBvM2z7DrLmwrY5PwzfrZrgdJzX7+r0hdRuC2GVb/mOopJSNuUe8QTIQdbuOsSanEMcOl78/Tn1q0fRtFYMTWvF0rRWDE1qxVC/enS5Xo1YYBhjAosq7N8KWfNg+1zna/5m57WwSKjTHlI7Qz3PIyrRv/X6iaqy88Ax1u06zNpdh1i7+xDrdh1m274CPHe0iAwPoVENJzya1IyhsedrzdgqF9Q3YoFhjAl8R3KdkVfb58OO+bBrOZR6/nWd2BDqdYKUjs6jRnMIdf/2TKA6VljCxtzDrNt9mPUnH3sOfz/MNzYyjOVP9rPAOB8WGMZUYEXHIGcp7FgAOxZB9sIf5oGER0GddlC3g/NIyXDWxapEnemnk19QyIY9h8kvKOSqVrUv6HdYYBhjKj5VZwHFnYudGejZi5wVeEucfTCIruEJkPbOLa06bSE6ya8lV0TnExiV9xrPGBPYRCAx3Xm0GuQcKz7hLGWSvRhyljhhsmEqzj5rQFwq1GnjdKTXbmshUs4sMIwxFUdYlR9uS510/BDsXuHcztq5BHYtg7Wf//B6bF1nNnrt1j98jatX6W9nXQgLDGNMxRYZ+8NEwZOOHXBCZNcKpzN913LYOM1ZWBEgMt5ZH6tWK6jZEmq2cOaHVII1si6GBYYxJvhUjYf0Xs7jpMIC2LMGdi+H3auc/pDMN6HYWdYcCXWWNanZwhmVdfJrfKpdjXhYYBhjKoeIaKjX0XmcVFrizFDfs8oJkT2rnc71VRPK/FwM1GgKNZpBcjPP16YQU6vSBYkFhjGm8grxXFUkNYIWN/xw/PhByF0HuWs8j7WwbjIsGfvDOZFxTnAkN/nha1ITp88kSJc+scAwxphTRcY5M89TO//4+JE8Z5Xe3HWQ53msm/LjIAmP8oRQY+dR/RLneWJDiIjy7fsoZxYYxhjjrWrJzqNs3wg4e6bnrYe962HvRuf77Qtg5fgfnxdX74cAqX6JEyLVGzrHK8BM9sCv0BhjAl10kvNI6/7j44VHYd8m2LcR9nq+7tsEyz+AE4d+OC8kHBLSILGBEyCJDZz5JwnpTqd7aLhP386ZWGAYY4xbIqKceR+1W//4uKqz7Mm+zU6A5G92vj+5RHzR0R/OlVCIr+eER2K6EyxlH5FxPns7rgaGiPQHXgJCgddV9dlTXn8UuBsoBvKA4aqa5XmtBFjpOXW7ql7nZq3GGOMzIlCthvOo3/XHr6nCkT1OeORvgfytztf9W2H1J3Bs/4/Pj4x3Rm4Nn+p62a4FhoiEAv8GrgCygUUiMklV15Q5bSmQoapHReSnwF+BWzyvHVPVtm7VZ4wxAUnEGbIb49l46lTHDjhrbB3Icr7uz3L2WvcBN68wOgGbVHULgIh8AAwEvg8MVf22zPnzgdtdrMcYYyq+qvFQ1bNOlo+5OVi4LrCjzPNsz7EzGQF8WeZ5pIhkish8EbnejQKNMcZ4z80rjNNNgTztWuoicjuQAVxa5nCqquaISAPgGxFZqaqbT/OzI4GRAKmpqRdftTHGmNNy8wojG6hX5nkKkHPqSSLSF/gNcJ2qnjh5XFVzPF+3ADOAdqdrRFVHqWqGqmYkJyeXX/XGGGN+xM3AWAQ0EpF0EYkAhgCTyp4gIu2A13DCIrfM8QQRqeL5PgnoTpm+D2OMMb7n2i0pVS0WkQeAaTjDaseo6moR+SOQqaqTgOeBasB4z160J4fPNgNeE5FSnFB79pTRVcYYY3zMtmg1xphK7Hy2aA3OJRWNMcaUOwsMY4wxXgmqW1IikgdkXeCPJwF7y7GciqAyvmeonO+7Mr5nqJzv+3zfc31V9WqIaVAFxsUQkUxv7+MFi8r4nqFyvu/K+J6hcr5vN9+z3ZIyxhjjFQsMY4wxXrHA+MEofxfgB5XxPUPlfN+V8T1D5Xzfrr1n68MwxhjjFbvCMMYY4xULDGOMMV6p9IEhIv1FZL2IbBKRx/1dj1tEpJ6IfCsia0VktYg87DmeKCJfi8hGz9cEf9da3kQkVESWisgXnufpIrLA854/9CyOGVREJF5EPhaRdZ7PvGuwf9Yi8ojnv+1VIjJORCKD8bMWkTEikisiq8ocO+1nK46XPX/fVohI+4tpu1IHRpltZAcAzYFbRaS5f6tyTTHwC1VtBnQB7ve818eB6araCJjueR5sHgbWlnn+HPAPz3vej7N5V7B5CZiqqk2BNjjvP2g/axGpCzyEs+VzS5wFT4cQnJ/1W0D/U46d6bMdADTyPEYCr1xMw5U6MCizjayqFgInt5ENOqq6S1WXeL4/jPMHpC7O+33bc9rbQFDtbigiKcDVwOue5wL0AT72nBKM7zkW6AW8AaCqhap6gCD/rHFW364qImFAFLCLIPysVfU7IP+Uw2f6bAcCY9UxH4gXkdoX2nZlD4zz3UY2KIhIGs6GVAuAmqq6C5xQAWr4rzJXvAj8Eij1PK8OHFDVYs/zYPzMGwB5wJueW3Gvi0g0QfxZq+pO4G/AdpygOAgsJvg/65PO9NmW69+4yh4YXm8jGyxEpBowAfi5qh7ydz1uEpFrgFxVXVz28GlODbbPPAxoD7yiqu2AAoLo9tPpeO7ZDwTSgTpANM7tmFMF22d9LuX633tlDwyvtpENFiISjhMW76nqRM/hPScvUT1fc8/08xVQd+A6EdmGc7uxD84VR7zntgUE52eeDWSr6gLP849xAiSYP+u+wFZVzVPVImAi0I3g/6xPOtNnW65/4yp7YJxzG9lg4bl3/wawVlVfKPPSJOAuz/d3AZ/5uja3qOoTqpqiqmk4n+03qnob8C0wyHNaUL1nAFXdDewQkSaeQ5fjbHEctJ81zq2oLiIS5flv/eR7DurPuowzfbaTgDs9o6W6AAdP3rq6EJV+preIXIXzr86T28g+4+eSXCEiPYBZwEp+uJ//a5x+jI+AVJz/6Qar6qkdahWeiPQGHlPVa0SkAc4VRyKwFLhdVU/4s77yJiJtcTr6I4AtwE9w/oEYtJ+1iDwF3IIzInApcDfO/fqg+qxFZBzQG2cZ8z3Ak8CnnOaz9YTnv3BGVR0FfqKqF7wtaaUPDGOMMd6p7LekjDHGeMkCwxhjjFcsMIwxxnjFAsMYY4xXLDCMMcZ4xQLDmHIgInM9X9NEZKi/6zHGDRYYxpQDVe3m+TYNOK/A8KyabEzAs8AwphyIyBHPt88CPUVkmWd/hlAReV5EFnn2I7jXc35vz/4k7+NMpjQm4IWd+xRjzHl4HM+McgARGYmzHENHEakCzBGRrzzndgJaqupWP9VqzHmxwDDGXf2A1iJycj2jOJzNbAqBhRYWpiKxwDDGXQI8qKrTfnTQWduqwC8VGXOBrA/DmPJ1GIgp83wa8FPP0vKISGPPZkbGVDh2hWFM+VoBFIvIcpy9l1/CGTm1xLNyaB5BsE2oqZxstVpjjDFesVtSxhhjvGKBYYwxxisWGMYYY7xigWGMMcYrFhjGGGO8YoFhjDHGKxYYxhhjvPL/0mmcgDQEUoQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(iter), reg.loss)\n",
    "plt.plot(np.arange(iter), reg.val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題8】（アドバンス課題）バイアス項の除去\n",
    "バイアス項 \n",
    "$\\theta_0$を抜くと学習がどう変化するか検証してください。また、線形回帰モデルにおけるバイアス項の役割の考察・調査を行ってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題9】（アドバンス課題）特徴量の多次元化\n",
    "特徴量の二乗や三乗を入力に利用すると学習結果がどう変化するか検証してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題10】（アドバンス課題）更新式の導出\n",
    "最急降下法の更新式は以下でした。この式が導出される過程を説明してください。\n",
    "$$\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\sum_{i=1}^m[(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}]$$\n",
    "\n",
    "以下の式から説明をはじめることができます。\n",
    "$$\\theta_j := \\theta_j - \\frac{\\partial}{\\partial\\theta_j}J(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "### 【問題11】（アドバンス課題）局所最適解の問題\n",
    "最急降下法には一般的に局所最適解の問題があります。しかし、線形回帰では学習を続ければ必ず最適解を求めることができます。それはなぜか数式やグラフを用いて説明してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
