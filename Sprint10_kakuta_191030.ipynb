{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint10 深層学習スクラッチ ディープニューラルネットワーク\n",
    "\n",
    "## 1.このSprintについて\n",
    "\n",
    "### Sprintの目的\n",
    "- スクラッチを通してニューラルネットワークの発展的内容を理解する\n",
    "\n",
    "### どのように学ぶか\n",
    "スクラッチで作成したニューラルネットワークの実装を拡張していきます。\n",
    "\n",
    "## 2.ディープニューラルネットワークスクラッチ\n",
    "前回は3層のニューラルネットワークを作成しましたが、今回はこれを任意の層数に拡張しやすいものに書き換えていきます。その上で、活性化関数や初期値、最適化手法について発展的なものを扱えるようにしていきます。\n",
    "\n",
    "このようなスクラッチを行うことで、今後各種フレームワークを利用していくにあたり、内部の動きが想像できることを目指します。\n",
    "\n",
    "名前は新しくScratchDeepNeuralNetrowkClassifierクラスとしてください。\n",
    "\n",
    "## 層などのクラス化\n",
    "クラスにまとめて行くことで、構成を変更しやすい実装にしていきます。\n",
    "\n",
    "**手を加える箇所**\n",
    "\n",
    "- 層の数\n",
    "- 層の種類（今後畳み込み層など他のタイプの層が登場する）\n",
    "- 活性化関数の種類\n",
    "- 重みやバイアスの初期化方法\n",
    "- 最適化手法\n",
    "そのために、全結合層、各種活性化関数、重みやバイアスの初期化、最適化手法それぞれのクラスを作成します。\n",
    "\n",
    "実装方法は自由ですが、簡単な例を紹介します。サンプルコード1のように全結合層と活性化関数のインスタンスを作成し、サンプルコード2,3のようにして使用します。それぞれのクラスについてはこのあと解説します。\n",
    "\n",
    "#### 《サンプルコード1》\n",
    "\n",
    "ScratchDeepNeuralNetrowkClassifierのfitメソッド内\n",
    "```\n",
    "# self.sigma : ガウス分布の標準偏差\n",
    "# self.lr : 学習率\n",
    "# self.n_nodes1 : 1層目のノード数\n",
    "# self.n_nodes2 : 2層目のノード数\n",
    "# self.n_output : 出力層のノード数\n",
    "\n",
    "optimizer = SGD(self.lr)\n",
    "self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation1 = Tanh()\n",
    "self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation2 = Tanh()\n",
    "self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "self.activation3 = Softmax()\n",
    "```\n",
    "#### 《サンプルコード2》\n",
    "\n",
    "イテレーションごとのフォワード\n",
    "```\n",
    "A1 = self.FC1.forward(X)\n",
    "Z1 = self.activation1.forward(A1)\n",
    "A2 = self.FC2.forward(Z1)\n",
    "Z2 = self.activation2.forward(A2)\n",
    "A3 = self.FC3.forward(Z2)\n",
    "Z3 = self.activation3.forward(A3)\n",
    "```\n",
    "#### 《サンプルコード3》\n",
    "\n",
    "イテレーションごとのバックワード\n",
    "```\n",
    "dA3 = self.activation3.backward(Z3, Y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "dZ2 = self.FC3.backward(dA3)\n",
    "dA2 = self.activation2.backward(dZ2)\n",
    "dZ1 = self.FC2.backward(dA2)\n",
    "dA1 = self.activation1.backward(dZ1)\n",
    "dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】全結合層のクラス化\n",
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself = self.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。\n",
    "\n",
    "### 《雛形》\n",
    "```\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        pass\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        pass\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.WH = 0\n",
    "        self.BH = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        A = self.X@self.W + self.B #shape(20, 400)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dA = dA\n",
    "        self.dW = np.mean(self.X, axis=0).T.reshape(-1, 1) @ self.dA\n",
    "        self.dB = self.dA #shape(1, 10)\n",
    "    \n",
    "        # 更新\n",
    "        dZ = self.dA @ self.W.T #shape(1, 200)\n",
    "        self = self.optimizer.update(self) \n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。\n",
    "\n",
    "#### 《雛形》\n",
    "```\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return B\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときにself = self.optimizer.update(self)のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。\n",
    "\n",
    "#### 雛形\n",
    "```\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        return layer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W = layer.W - self.lr*layer.dW\n",
    "        layer.B = layer.B - self.lr*layer.dB\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh():\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * (1 - np.tanh(np.mean(self.A, axis=0))**2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def forward(self, A):\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, Z, Y):\n",
    "        dA = np.mean(Z - Y, axis=0).reshape(1, -1) #shape(1, 10)\n",
    "        self.loss = -1 * np.mean(np.sum(Y * np.log(Z), axis=1))\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 発展的要素\n",
    "活性化関数や重みの初期値、最適化手法に関してこれまで見てきた以外のものを実装していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "ReLUは以下の数式です。\n",
    "$$f(x) = ReLU(x) = \\begin{cases}x & if x > 0\\\\\n",
    "0 & if x \\leq 0\n",
    "  \\end{cases}$$\n",
    "  \n",
    "$x$ : ある特徴量。スカラー\n",
    "\n",
    "実装上はnp.maximumを使い配列に対してまとめて計算が可能です。\n",
    "\n",
    "[numpy.maximum — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.maximum.html)\n",
    "\n",
    "一方、バックプロパゲーションのための $x$ に関する$f(x)$ の微分は以下のようになります。\n",
    "$$\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}1 & if x > 0\\\\\n",
    "0 & if x \\leq 0\n",
    "  \\end{cases}$$\n",
    "  \n",
    "数学的には微分可能ではないですが、 $x=0$ のとき0 とすることで対応しています。\n",
    "\n",
    "フォワード時の $x$ の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        Z = np.where(self.X>0, self.X, 0)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * np.where(self.X>0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavierの初期値\n",
    "Xavierの初期値における標準偏差 $\\sigma$ は次の式で求められます。\n",
    "$$\\sigma = \\frac{1}{\\sqrt{n}}$$\n",
    "\n",
    "$n$ : 前の層のノード数\n",
    "\n",
    "#### 《論文》\n",
    "\n",
    "[Glorot, X., & Bengio, Y. (n.d.). Understanding the difficulty of training deep feedforward neural networks.](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "\n",
    "### Heの初期値\n",
    "Heの初期値における標準偏差 $\\sigma$ は次の式で求められます。\n",
    "$$\\sigma = \\sqrt{\\frac{2}{n}}$$\n",
    "\n",
    "$n$ : 前の層のノード数\n",
    "\n",
    "#### 《論文》\n",
    "\n",
    "[He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.](https://arxiv.org/pdf/1502.01852.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer():\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer():\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2/n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である AdaGrad のクラスを作成してください。\n",
    "\n",
    "まず、これまで使ってきたSGDを確認します。\n",
    "$$W'_i = W_i - \\alpha E\\left(\\frac{\\partial L}{\\partial W_i}\\right)$$\n",
    "$$B'_i = B_i - \\alpha E\\left(\\frac{\\partial L}{\\partial B_i}\\right)$$\n",
    "\n",
    "$\\alpha$  : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "$\\frac{\\partial L}{\\partial W_i}$ : $W_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial B_i}$ : $B_i$ に関する損失 $L$ の勾配\n",
    "\n",
    "$E()$  : ミニバッチ方向にベクトルの平均を計算\n",
    "\n",
    "続いて、AdaGradです。バイアスの数式は省略しますが、重みと同様のことをします。\n",
    "\n",
    "更新された分だけその重みに対する学習率を徐々に下げていきます。イテレーションごとの勾配の二乗和 $H$ を保存しておき、その分だけ学習率を小さくします。\n",
    "\n",
    "学習率は重み一つひとつに対して異なることになります。\n",
    "$$H'_i = H_i + E\\left(\\frac{\\partial L}{\\partial W_i}\\right) × E\\left(\\frac{\\partial L}{\\partial W_i}\\right)$$\n",
    "$$W'_i = W_i - \\alpha \\frac{1}{\\sqrt{H'_i}} E \\left(\\frac{\\partial L}{\\partial W_i}\\right)$$\n",
    "\n",
    "$H_i$  : i層目に関して、前のイテレーションまでの勾配の二乗和（初期値は0）\n",
    "\n",
    "$H'_i$ : 更新した $H_i$\n",
    "\n",
    "#### 《論文》\n",
    "\n",
    "[Duchi JDUCHI, J., & Singer, Y. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization * Elad Hazan. Journal of Machine Learning Research (Vol. 12).](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad():\n",
    "    def __init__(self):\n",
    "        self.lr = 0.01\n",
    "        self.WH = np.zeros(1)\n",
    "        self.BH = np.zeros(1)\n",
    "        pass\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.WH = layer.WH + layer.dW * layer.dW\n",
    "        layer.BH = layer.BH + layer.dB * layer.dB\n",
    "        layer.W = layer.W - self.lr*np.sqrt(layer.WH) * layer.dW\n",
    "        layer.B = layer.B - self.lr*np.sqrt(layer.BH) * layer.dB\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.検証\n",
    "\n",
    "### 【問題9】学習と推定\n",
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, epoch=2, lr=0.01, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.mini_y_train = None\n",
    "        self.train_loss_list = []\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        self.n_features = X.shape[1]\n",
    "        self.n_nodes1 = 400\n",
    "        self.n_nodes2 = 200\n",
    "        self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "        batch_size = 20\n",
    "        self.n_output = 10\n",
    "        \n",
    "        optimizer = SGD(self.lr)\n",
    "        \n",
    "        get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "        if self.verbose:\n",
    "            print(\"train data learning process\\n\")\n",
    "            \n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, XavierInitializer(), optimizer)\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, XavierInitializer(), optimizer)\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, XavierInitializer(), optimizer)\n",
    "        \n",
    "        for _ in range(self.epoch):\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                self.mini_y_train = mini_y_train\n",
    "                \n",
    "                self.activation1 = Tanh()\n",
    "                A1 = self.FC1.forward(mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                \n",
    "                self.activation2 = Tanh()\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                \n",
    "                self.activation3 = Softmax()\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                \n",
    "                dA3 = self.activation3.backward(Z3, self.mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "                \n",
    "                if self.verbose:\n",
    "                    verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(\"W1\\n{}\\n\".format(self.W1))\n",
    "                    print(\"W2\\n{}\\n\".format(self.W2))\n",
    "                    print(\"W3\\n{}\\n\".format(self.W3))\n",
    "                    print(\"B1\\n{}\\n\".format(self.B1))\n",
    "                    print(\"B2\\n{}\\n\".format(self.B2))\n",
    "                    print(\"B3\\n{}\\n\".format(self.B3))\n",
    "                    pass\n",
    "            self.train_loss_list.append(self.activation3.loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        \n",
    "        y_pred = Z3\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練用データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8811666666666667\n"
     ]
    }
   ],
   "source": [
    "nn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, epoch=3, verbose=False)\n",
    "nn.fit(X_train, y_train, X_val, y_val)\n",
    "y_pred = nn.predict(X_val)\n",
    "print(\"Accuracy:{}\".format(metrics.accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"loss process\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(nn.train_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier1():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers=3, n_nodes=200, epoch=2, lr=0.01, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.mini_y_train = None\n",
    "        self.train_loss_list = []\n",
    "        self.n_layers = n_layers\n",
    "        self.n_nodes = n_nodes\n",
    "        self.FC_list = []\n",
    "        self.activation_list = []\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "        \n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "        self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "        batch_size = 20\n",
    "        self.n_output = 10\n",
    "        \n",
    "        optimizer = SGD(self.lr)\n",
    "        \n",
    "        get_mini_batch = GetMiniBatch(X, y_train_one_hot, batch_size=20)\n",
    "        if self.verbose:\n",
    "            print(\"train data learning process\\n\")\n",
    "            \n",
    "        for i in range(self.n_layers):\n",
    "            if i==0:\n",
    "                self.FC_list.append(FC(self.n_features, self.n_nodes, XavierInitializer(), optimizer))\n",
    "                self.activation_list.append(Tanh())\n",
    "            \n",
    "            elif i==self.n_layers-1:\n",
    "                self.FC_list.append(FC(self.n_nodes, self.n_output, XavierInitializer(), optimizer))\n",
    "                self.activation_list.append(Softmax())\n",
    "            else:\n",
    "                self.FC_list.append(FC(self.n_nodes, self.n_nodes, XavierInitializer(), optimizer))\n",
    "                self.activation_list.append(Tanh())\n",
    "        \n",
    "        for _ in range(self.epoch):\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                self.mini_y_train = mini_y_train\n",
    "                \n",
    "                for i in range(self.n_layers):\n",
    "                    if i==0:\n",
    "                        A = self.FC_list[i].forward(mini_X_train)\n",
    "                        Z = self.activation_list[i].forward(A)\n",
    "                    else:\n",
    "                        A = self.FC_list[i].forward(Z)\n",
    "                        Z = self.activation_list[i].forward(A)\n",
    "                        \n",
    "                for i in range(self.n_layers):\n",
    "                    if i==0:\n",
    "                        dA = self.activation_list[-(i+1)].backward(Z, self.mini_y_train)\n",
    "                        dZ = self.FC_list[-(i+1)].backward(dA)\n",
    "                    else:\n",
    "                        dA = self.activation_list[-(i+1)].backward(dZ)\n",
    "                        dZ = self.FC_list[-(i+1)].backward(dA)\n",
    "                \n",
    "                if self.verbose:\n",
    "                    verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(\"W1\\n{}\\n\".format(self.W1))\n",
    "                    print(\"W2\\n{}\\n\".format(self.W2))\n",
    "                    print(\"W3\\n{}\\n\".format(self.W3))\n",
    "                    print(\"B1\\n{}\\n\".format(self.B1))\n",
    "                    print(\"B2\\n{}\\n\".format(self.B2))\n",
    "                    print(\"B3\\n{}\\n\".format(self.B3))\n",
    "                    \n",
    "            self.train_loss_list.append(self.activation_list[-1].loss)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for i in range(self.n_layers):\n",
    "            if i==0:\n",
    "                A = self.FC_list[i].forward(X)\n",
    "                Z = self.activation_list[i].forward(A)\n",
    "            else:\n",
    "                A = self.FC_list[i].forward(Z)\n",
    "                Z = self.activation_list[i].forward(A)\n",
    "                \n",
    "        y_pred = Z\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.89675\n"
     ]
    }
   ],
   "source": [
    "nn1 = ScratchDeepNeuralNetrowkClassifier1(n_layers=5, n_nodes=200, epoch=30, lr=0.01, verbose=False)\n",
    "nn1.fit(X_train, y_train, X_val, y_val)\n",
    "y_pred = nn1.predict(X_val)\n",
    "print(\"Accuracy:{}\".format(metrics.accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"loss process\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(nn1.train_loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
